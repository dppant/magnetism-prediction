{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41f5adc1",
   "metadata": {},
   "source": [
    "## Exhustive search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "febb6c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/python\n",
    "# -*- coding: utf-8 -*-\n",
    "import itertools\n",
    "\n",
    "def findMatchings(X):\n",
    "    A = [0,0,0,0,1,1,1,1,2,2,2,2,3,3,3,3,4,4,4,4]\n",
    "    n = len(A)\n",
    "    combinations = []\n",
    "    for i in range(n - 3):\n",
    "        for j in range(i + 1, n - 2):\n",
    "            l = j + 1\n",
    "            r = n - 1\n",
    "            while l < r:\n",
    "                if A[i] + A[j] + A[l] + A[r] == X:\n",
    "                    if [A[i], A[j], A[l], A[r]] not in combinations:\n",
    "                        combinations.append([A[i], A[j], A[l], A[r]])\n",
    "                    l += 1\n",
    "                    r -= 1\n",
    "                elif A[i] + A[j] + A[l] + A[r] < X:\n",
    "                    l += 1\n",
    "                else:\n",
    "                    r -= 1\n",
    "\n",
    "  # calculate permutations of each found combinations\n",
    "  # print(combinations)\n",
    "\n",
    "    permutations = []\n",
    "    for item in combinations:\n",
    "        temp = list(itertools.permutations(item))\n",
    "        t = [list(e) for e in temp]\n",
    "        permutations.extend(t)\n",
    "\n",
    "    return list(map(list, set(map(tuple, permutations))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "59af2790",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 2, 2, 0], [0, 0, 4, 0], [1, 0, 2, 1], [2, 2, 0, 0], [2, 0, 1, 1], [2, 0, 2, 0], [0, 2, 1, 1], [0, 0, 3, 1], [0, 0, 2, 2], [1, 0, 0, 3], [0, 3, 1, 0], [1, 0, 1, 2], [1, 1, 2, 0], [0, 1, 2, 1], [0, 1, 3, 0], [3, 0, 0, 1], [0, 4, 0, 0], [3, 0, 1, 0], [1, 2, 1, 0], [0, 3, 0, 1], [3, 1, 0, 0], [2, 0, 0, 2], [1, 1, 1, 1], [0, 2, 0, 2], [0, 1, 1, 2], [0, 0, 0, 4], [2, 1, 1, 0], [0, 0, 1, 3], [4, 0, 0, 0], [1, 2, 0, 1], [0, 1, 0, 3], [1, 1, 0, 2], [1, 0, 3, 0], [2, 1, 0, 1], [1, 3, 0, 0]]\n",
      "35\n"
     ]
    }
   ],
   "source": [
    "results = findMatchings(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8f915e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import trunc\n",
    "import random\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "def generate_new_input():\n",
    "    \n",
    "    '''\n",
    "    This functions creates a bimetallic chalcogenides by randomly choosing a transition metal, its comcentration\n",
    "    and chalcogen element.  \n",
    "    '''\n",
    "    trans_metals = ['Ni', 'Co', 'Cr', 'Mn']\n",
    "    chalcogens = ['S', 'Se', 'Te']\n",
    "\n",
    "    y_all = np.linspace(6, 62.5, 1131)\n",
    "    \n",
    "    for A in trans_metals:\n",
    "        for B in chalcogens:\n",
    "            for y in y_all:\n",
    "                x= 100-y  # percentage of Fe\n",
    "                n = round(16*y/100) # Total number of substituted transition metalfor given substitution\n",
    "                # call function to find all possible permutation of four integers that sums to n\n",
    "                S_all = findMatchings(n)\n",
    "\n",
    "                for S_item in S_all:\n",
    "                    S1,S2,S3,S4 = S_item\n",
    "#                     return [A,B,x,y,S1,S2,S3,S4]\n",
    "                    sample = [A,B,x/100,y/100,S1,S2,S3,S4]\n",
    "                    \n",
    "                    # create new dataframe\n",
    "                    cols = ['Fe','S1','S2','S3','S4','Ni','Co','Cr','Mn','Se','S','Te'] # list for cols to scale\n",
    "                    df_new = pd.DataFrame(columns=cols)\n",
    "                    data = [0]*12\n",
    "                    df_new.loc[len(df_new)] = data\n",
    "                    \n",
    "                    transition_metal = sample[0]\n",
    "                    chalcogen = sample[1]\n",
    "\n",
    "                    df_new['Fe'] = sample[2]\n",
    "                    df_new[transition_metal] = sample[3]\n",
    "                    df_new[chalcogen] = 1\n",
    "                    df_new['S1'] = sample[4]\n",
    "                    df_new['S2'] = sample[5]\n",
    "                    df_new['S3'] = sample[6]\n",
    "                    df_new['S4'] = sample[7]\n",
    "\n",
    "                    X_test = df_new.copy()\n",
    "\n",
    "                    # load standard scaler\n",
    "                    scaler = pkl.load(open('../models/standard_scaler/scaler.pkl', 'rb'))\n",
    "\n",
    "                    # transform input data using saved standard scaler\n",
    "                    cols_to_scale = ['Fe','S1','S2','S3','S4','Ni','Co','Cr','Mn','Se','S','Te'] # list for cols to scale\n",
    "                    X_test[cols_to_scale] = scaler.transform(X_test[cols_to_scale]) # scale test data\n",
    "\n",
    "\n",
    "                    # load base models\n",
    "                    ANN_model = load_model(\"../models/base_models/ann.h5\")\n",
    "                    svr = pkl.load(open('../models/base_models/svr.pkl', 'rb'))\n",
    "                    rf_reg = pkl.load(open('../models/base_models/rf_reg.pkl', 'rb'))\n",
    "                    knn_reg = pkl.load(open('../models/base_models/knn_reg.pkl', 'rb'))\n",
    "                    xgb_reg = pkl.load(open('../models/base_models/xgb_reg.pkl', 'rb'))\n",
    "                    dt_reg = pkl.load(open('../models/base_models/dt_reg.pkl', 'rb'))\n",
    "\n",
    "                    # load meta model\n",
    "                    rf_meta_final = pkl.load(open('../models/meta_model/rf_meta_final.pkl', 'rb'))\n",
    "\n",
    "                    # prepare new features based on base classifiers for test set\n",
    "                    y_pred_test_ann = ANN_model.predict(X_test, verbose=0)\n",
    "                    y_pred_test_ann = y_pred_test_ann.reshape(y_pred_test_ann.shape[0],)\n",
    "                    y_pred_test_svm = svr.predict(X_test)\n",
    "                    y_pred_test_rf = rf_reg.predict(X_test)\n",
    "                    y_pred_test_knn = knn_reg.predict(X_test)\n",
    "                    y_pred_test_xgb = xgb_reg.predict(X_test)\n",
    "                    y_pred_test_dt = dt_reg.predict(X_test)\n",
    "\n",
    "                    # get new features from base models\n",
    "                    X_test_stacking = pd.DataFrame()\n",
    "                    X_test_stacking['ann'] = y_pred_test_ann\n",
    "                    X_test_stacking['svm'] = y_pred_test_svm\n",
    "                    X_test_stacking['rf'] = y_pred_test_rf\n",
    "                    X_test_stacking['knn'] = y_pred_test_knn\n",
    "                    X_test_stacking['xgb'] = y_pred_test_xgb\n",
    "                    X_test_stacking['dt'] = y_pred_test_dt\n",
    "\n",
    "                    # apply new features to meta classifier\n",
    "                    final_prediction = rf_meta_final.predict(X_test_stacking)\n",
    "\n",
    "                   # write results to file\n",
    "                    df_new['M_predicted'] = final_prediction\n",
    "                    df_new.to_csv(\"output/exhaustive_search_results.csv\", mode='a+', index=False, header= False)\n",
    "\n",
    "\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cb8050fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001890224F040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000189022A6F70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [48]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mgenerate_new_input\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [47]\u001b[0m, in \u001b[0;36mgenerate_new_input\u001b[1;34m()\u001b[0m\n\u001b[0;32m     60\u001b[0m ANN_model \u001b[38;5;241m=\u001b[39m load_model(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../models/base_models/ann.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     61\u001b[0m svr \u001b[38;5;241m=\u001b[39m pkl\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../models/base_models/svr.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m---> 62\u001b[0m rf_reg \u001b[38;5;241m=\u001b[39m \u001b[43mpkl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m../models/base_models/rf_reg.pkl\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     63\u001b[0m knn_reg \u001b[38;5;241m=\u001b[39m pkl\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../models/base_models/knn_reg.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m     64\u001b[0m xgb_reg \u001b[38;5;241m=\u001b[39m pkl\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../models/base_models/xgb_reg.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\base.py:325\u001b[0m, in \u001b[0;36mBaseEstimator.__setstate__\u001b[1;34m(self, state)\u001b[0m\n\u001b[0;32m    322\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    323\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m state\n\u001b[1;32m--> 325\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__setstate__\u001b[39m(\u001b[38;5;28mself\u001b[39m, state):\n\u001b[0;32m    326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__module__\u001b[39m\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msklearn.\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    327\u001b[0m         pickle_version \u001b[38;5;241m=\u001b[39m state\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_sklearn_version\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpre-0.18\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "generate_new_input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "02b50cc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1131,)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_all.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "248863e7",
   "metadata": {},
   "source": [
    "## Following code generates input data randomly for possible configuration of bimetal chalcogenides and calculates magnetic moment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b403fe84-1a58-4ac5-8a70-abcdc49aeab7",
   "metadata": {},
   "source": [
    "### Suresh and Dharmendra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f397d46b-1077-422e-abc9-635a3c0697c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import trunc\n",
    "import random\n",
    "\n",
    "def generate_new_input():\n",
    "    \n",
    "    '''\n",
    "    This functions creates a bimetallic chalcogenides by randomly choosing a transition metal, its comcentration\n",
    "    and chalcogen element.  \n",
    "    '''\n",
    "    # Enter transition metal\n",
    "    # A = input(\"Enter transition metal: Ni, Co, Cr or Mn \\n\")\n",
    "\n",
    "    trans_metal_dic = {1:'Ni', 2:'Co', 3:'Cr', 4:'Mn'}\n",
    "    chalcogens_dic = {5:'S', 6: 'Se', 7:'Te'}\n",
    "\n",
    "    # generate random number (0,1,2,3) and assign accordingly (Ni, Co, Cr, Mn)\n",
    "    temp_1 = random.sample(range(1, 5), 1)[0]\n",
    "    A = trans_metal_dic[temp_1]\n",
    "\n",
    "    temp_2 = random.sample(range(5, 8), 1)[0]\n",
    "    B = chalcogens_dic[temp_2]\n",
    "\n",
    "\n",
    "    y = random.uniform(10,62.5) #Concentration of Substituted transition metal\n",
    "    x= 100-y  # percentage of Fe\n",
    "\n",
    "\n",
    "\n",
    "    n = 16*y/100 # Total number of substituted transition metalfor given substitution\n",
    "\n",
    "    max_limit = 100*4/n # Calculate maximum nuber of transition metal on sites\n",
    "\n",
    "## randomly fill sites (s1, s2, s3, s4) with atoms based on the % of sunstituted metal, No sites contains more than\n",
    "## 4 atoms as this generalization is based on the FeS unit cell containing 16 Fe atoms, 4 sites and a site can hold only \n",
    "#4 atoms\n",
    "    \n",
    "    S1 = random.uniform(0, min(max_limit,100))\n",
    "\n",
    "    rem_A = 100-S1 # Remaining percentage of transition metal\n",
    "    \n",
    "    n1 = n * rem_A / 100 # Remaining number of transition metal\n",
    "\n",
    "    S2 = random.uniform(0, min(max_limit, rem_A))\n",
    "\n",
    "    rem_A = 100 - S1 - S2\n",
    "    n2 = n * rem_A / 100\n",
    "\n",
    "    S3 = random.uniform(0, min(rem_A, max_limit))\n",
    "\n",
    "    rem_A = 100-S1-S2-S3\n",
    "\n",
    "    S4 = random.uniform(0, min(rem_A, max_limit))\n",
    "    S4 = rem_A\n",
    "\n",
    "\n",
    "    rem_A = 100-S1-S2-S3-S4 # check total % of Tran metal\n",
    "\n",
    "\n",
    "    # Convert Percentage into numbers\n",
    "    y_transformed = (y*16/100)/16\n",
    "    x_transformed = 1-y_transformed\n",
    "    S1_tranformed = S1*n/100\n",
    "    S2_tranformed = S2*n/100\n",
    "    S3_tranformed = S3*n/100\n",
    "    S4_tranformed = S4*n/100\n",
    "\n",
    "    if S4_tranformed > 4:      # As our model based on the unit cell FeS used in calculation, its a constraints\n",
    "        # call model\n",
    "#         print(\"Invalid input\")\n",
    "        return 0\n",
    "    else:\n",
    "        return [A,B,x_transformed,y_transformed,S1_tranformed,S2_tranformed,S3_tranformed,S4_tranformed]\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fca416ae-939a-4015-ab33-f410bb0bde26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_magnetic_moment(N_samples, output_file):\n",
    "    \n",
    "    \"\"\"\n",
    "    This funtion takes numbers of bimetallic chalcogeneides to investigate, and then caclulates magnetic moment\n",
    "    of chalcogenides generated by 'generate_new_input()' using our final stacked machine learning model.\"\"\"\n",
    "    import pandas as pd\n",
    "    import pickle as pkl\n",
    "    from sklearn.metrics import r2_score, mean_absolute_error,mean_squared_error\n",
    "    from tensorflow.keras.models import load_model\n",
    "    \n",
    "    for iteration in range(N_samples):\n",
    "\n",
    "        # create random dataset here\n",
    "        cols = ['Fe','S1','S2','S3','S4','Ni','Co','Cr','Mn','Se','S','Te'] # list for cols to scale\n",
    "        df_new = pd.DataFrame(columns=cols)\n",
    "        data = [0]*12\n",
    "        df_new.loc[len(df_new)] = data\n",
    "        sample = generate_new_input()\n",
    "        \n",
    "        if sample == 0:\n",
    "            continue\n",
    "        \n",
    "        transition_metal = sample[0]\n",
    "        chalcogen = sample[1]\n",
    "\n",
    "        df_new['Fe'] = sample[2]\n",
    "        df_new[transition_metal] = sample[3]\n",
    "        df_new[chalcogen] = 1\n",
    "        df_new['S1'] = sample[4]\n",
    "        df_new['S2'] = sample[5]\n",
    "        df_new['S3'] = sample[6]\n",
    "        df_new['S4'] = sample[7]\n",
    "\n",
    "        X_test = df_new.copy()\n",
    "\n",
    "        # load standard scaler\n",
    "        scaler = pkl.load(open('../models/standard_scaler/scaler.pkl', 'rb'))\n",
    "\n",
    "        # transform input data using saved standard scaler\n",
    "        cols_to_scale = ['Fe','S1','S2','S3','S4','Ni','Co','Cr','Mn','Se','S','Te'] # list for cols to scale\n",
    "        X_test[cols_to_scale] = scaler.transform(X_test[cols_to_scale]) # scale test data\n",
    "\n",
    "\n",
    "        # load base models\n",
    "        ANN_model = load_model(\"../models/base_models/ann.h5\")\n",
    "        svr = pkl.load(open('../models/base_models/svr.pkl', 'rb'))\n",
    "        rf_reg = pkl.load(open('../models/base_models/rf_reg.pkl', 'rb'))\n",
    "        knn_reg = pkl.load(open('../models/base_models/knn_reg.pkl', 'rb'))\n",
    "        xgb_reg = pkl.load(open('../models/base_models/xgb_reg.pkl', 'rb'))\n",
    "        dt_reg = pkl.load(open('../models/base_models/dt_reg.pkl', 'rb'))\n",
    "\n",
    "        # load meta model\n",
    "        rf_meta_final = pkl.load(open('../models/meta_model/rf_meta_final.pkl', 'rb'))\n",
    "\n",
    "        # prepare new features based on base classifiers for test set\n",
    "        y_pred_test_ann = ANN_model.predict(X_test, verbose=0)\n",
    "        y_pred_test_ann = y_pred_test_ann.reshape(y_pred_test_ann.shape[0],)\n",
    "        y_pred_test_svm = svr.predict(X_test)\n",
    "        y_pred_test_rf = rf_reg.predict(X_test)\n",
    "        y_pred_test_knn = knn_reg.predict(X_test)\n",
    "        y_pred_test_xgb = xgb_reg.predict(X_test)\n",
    "        y_pred_test_dt = dt_reg.predict(X_test)\n",
    "\n",
    "        # get new features from base models\n",
    "        X_test_stacking = pd.DataFrame()\n",
    "        X_test_stacking['ann'] = y_pred_test_ann\n",
    "        X_test_stacking['svm'] = y_pred_test_svm\n",
    "        X_test_stacking['rf'] = y_pred_test_rf\n",
    "        X_test_stacking['knn'] = y_pred_test_knn\n",
    "        X_test_stacking['xgb'] = y_pred_test_xgb\n",
    "        X_test_stacking['dt'] = y_pred_test_dt\n",
    "\n",
    "        # apply new features to meta classifier\n",
    "        final_prediction = rf_meta_final.predict(X_test_stacking)\n",
    "\n",
    "       # write results to file\n",
    "        df_new['M_predicted'] = final_prediction\n",
    "        df_new.to_csv(output_file, mode='a+', index=False, header= False)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e126d07e",
   "metadata": {},
   "source": [
    "#### Finally, we can use the \"find_magnetic_moment\" to calculate magnetic moment as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d54ce6d-5ba2-4dec-9989-8f074a79e13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "find_magnetic_moment(30000, 'output/test_random.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e131df",
   "metadata": {},
   "source": [
    "### Following code is used to create Bimetallic Chalcogenides mannually by entering the values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5899607",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter transition metal: Ni, Co, Cr or Mn \n",
      "Ni\n",
      "Enter Chalcogen: S, Se or  Te \n",
      "S\n",
      "Concentration of Ni less than equals to 62.5% \n",
      "34\n",
      "Enter % of Ni for atomic site S1: \n",
      " S1 should be <= 73% \n",
      "65\n",
      "\n",
      "Enter % of Ni for atomic site S2: \n",
      " S2 should be <= 73% \n",
      "Now you have only 35% of Ni left \n",
      "23\n",
      "Enter % of Ni for atomic site S3: \n",
      " S3 should be <= 73% \n",
      "Now you have only 12% of Ni left \n",
      "7\n",
      "Enter % of Ni for atomic site S4: \n",
      " S4 should be <= 73% \n",
      "Now you have only 5% of Ni left5\n",
      "=====================================\n",
      "Transition metal:  Ni \n",
      "Chalcogen:  S \n",
      "x:  0.6599999999999999 \n",
      "y:  0.34 \n",
      "S1:  3.536 \n",
      "S2:  1.2512 \n",
      "S3:  0.3808 \n",
      "S4: 0.272\n"
     ]
    }
   ],
   "source": [
    "from math import trunc\n",
    "# Enter transition metal\n",
    "A = input(\"Enter transition metal: Ni, Co, Cr or Mn \\n\")\n",
    "\n",
    "# Enter Chalcogen element\n",
    "if A not in ['Ni', 'Co', 'Cr', 'Mn']:\n",
    "    raise Exception(\"Invalid entry, choose one transition element\")\n",
    "\n",
    "B= input(\"Enter Chalcogen: S, Se or  Te \\n\")\n",
    "if B not in ['S', 'Se', 'Te']:\n",
    "    raise Exception(\"Invalid entry, choose one chalcogen element\")\n",
    "\n",
    "# Enter the percentage of substituted transition metal\n",
    "y= int(input(\"Concentration of {} less than equals to 62.5% \\n\".format(A)))\n",
    "x= 100-y  # percentage of Fe\n",
    "\n",
    "if y> 62.5:\n",
    "    raise Exception(\" Enter y less than 62.5\")\n",
    "\n",
    "n = 16*y/100 # Total number of substituted transition metal\n",
    "max_limit = 100*4/n # Calculate maximum nuber of transition metal on sites\n",
    "\n",
    "# Assign the percentage of transition metal at the atomic site S1\n",
    "S1= eval(input(\"Enter % of {} for atomic site S1: \\n S1 should be <= {}% \\n\".format(A,trunc(max_limit))))\n",
    "\n",
    "if S1> max_limit:\n",
    "    raise Exception(\" Value out of range: please check S1's maximum value\")\n",
    "\n",
    "rem_A = 100-S1 # Remaining percentage of transition metal\n",
    "n1 = n*rem_A/100 # Remaining number of transition metal\n",
    "print()\n",
    "# Assign the percentage of transition metal at the atomic site S2\n",
    "S2= eval(input(\"Enter % of {} for atomic site S2: \\n S2 should be <= {}% \\n\"\n",
    "               \"Now you have only {}% of {} left \\n\".format(A,trunc(max_limit),rem_A, A)))\n",
    "\n",
    "rem_A = 100-S1-S2\n",
    "n2 = n*rem_A/100\n",
    "if rem_A < 0 or S2 > trunc(max_limit):\n",
    "    raise Exception(\" Value out of range: please enter appropriate value\")\n",
    "\n",
    "\n",
    "# Assign the percentage of transition metal at the atomic site S3\n",
    "S3 = eval(input(\"Enter % of {} for atomic site S3: \\n S3 should be <= {}% \\n\"\n",
    "                \"Now you have only {}% of {} left \\n\".format(A, trunc(max_limit), rem_A, A)))\n",
    "\n",
    "rem_A = 100-S1-S2-S3\n",
    "if rem_A <0 or S2 > trunc(max_limit):\n",
    "    raise Exception(\" Value out of range: please enter appropriate value\")\n",
    "\n",
    "\n",
    "# Assign the percentage of transition metal at the atomic site S4\n",
    "S4= eval(input(\"Enter % of {} for atomic site S4: \\n S4 should be <= {}% \\n\"\n",
    "               \"Now you have only {}% of {} left\".format(A,trunc(max_limit),rem_A, A)))\n",
    "\n",
    "rem_A = 100-S1-S2-S3-S4\n",
    "if rem_A <0 or S2 > trunc(max_limit):\n",
    "    raise Exception(\" Value out of range: please enter appropriate value\")\n",
    "\n",
    "# Convert Percentage into numbers\n",
    "y_transformed = (y*16/100)/16\n",
    "x_transformed = 1-y_transformed\n",
    "S1_tranformed = S1*n/100\n",
    "S2_tranformed = S2*n/100\n",
    "S3_tranformed = S3*n/100\n",
    "S4_tranformed = S4*n/100\n",
    "print('=====================================')\n",
    "\n",
    "print(\"Transition metal: \", A,\"\\nChalcogen: \", B, \"\\nx: \", x_transformed, \"\\ny: \", y_transformed,\n",
    "      \"\\nS1: \", S1_tranformed, \"\\nS2: \", S2_tranformed, \"\\nS3: \", S3_tranformed, \"\\nS4:\", S4_tranformed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e7db6e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
