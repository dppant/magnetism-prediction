{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "248863e7",
   "metadata": {},
   "source": [
    "## Following code generates input data for all possible configuration of bimetal chalcogenides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5899607",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter transition metal: Ni, Co, Cr or Mn \n",
      "Cr\n",
      "Enter Chalcogen: S, Se or  Te \n",
      "Se\n",
      "Concentration of Cr less than equals to 62.5% \n",
      "56\n",
      "Enter % of Cr for atomic site S1: \n",
      " S1 should be <= 44% \n",
      "34\n",
      "\n",
      "Enter % of Cr for atomic site S2: \n",
      " S2 should be <= 44% \n",
      "Now you have only 66% of Cr left \n",
      "43\n",
      "Enter % of Cr for atomic site S3: \n",
      " S3 should be <= 44% \n",
      "Now you have only 23% of Cr left \n",
      "12\n",
      "Enter % of Cr for atomic site S2: \n",
      " S4 should be <= 44% \n",
      "Now you have only 11% of Cr left11\n",
      "=====================================\n",
      "Transition metal:  Cr \n",
      "Chalcogen:  Se \n",
      "x:  0.43999999999999995 \n",
      "y:  0.56 \n",
      "S1:  3.0464 \n",
      "S2:  3.8528000000000002 \n",
      "S3:  1.0752000000000002 \n",
      "S4: 0.9856\n"
     ]
    }
   ],
   "source": [
    "from math import trunc\n",
    "# Enter transition metal\n",
    "A = input(\"Enter transition metal: Ni, Co, Cr or Mn \\n\")\n",
    "\n",
    "# Enter Chalcogen element\n",
    "if A not in ['Ni', 'Co', 'Cr', 'Mn']:\n",
    "    raise Exception(\"Invalid entry, choose one transition element\")\n",
    "\n",
    "B= input(\"Enter Chalcogen: S, Se or  Te \\n\")\n",
    "if B not in ['S', 'Se', 'Te']:\n",
    "    raise Exception(\"Invalid entry, choose one chalcogen element\")\n",
    "\n",
    "# Enter the percentage of substituted transition metal\n",
    "y= int(input(\"Concentration of {} less than equals to 62.5% \\n\".format(A)))\n",
    "x= 100-y  # percentage of Fe\n",
    "\n",
    "if y> 62.5:\n",
    "    raise Exception(\" Enter y less than 62.5\")\n",
    "\n",
    "n = 16*y/100 # Total number of substituted transition metal\n",
    "max_limit = 100*4/n # Calculate maximum nuber of transition metal on sites\n",
    "\n",
    "# Assign the percentage of transition metal at the atomic site S1\n",
    "S1= eval(input(\"Enter % of {} for atomic site S1: \\n S1 should be <= {}% \\n\".format(A,trunc(max_limit))))\n",
    "\n",
    "if S1> max_limit:\n",
    "    raise Exception(\" Value out of range: please check S1's maximum value\")\n",
    "\n",
    "rem_A = 100-S1 # Remaining percentage of transition metal\n",
    "n1 = n*rem_A/100 # Remaining number of transition metal\n",
    "print()\n",
    "# Assign the percentage of transition metal at the atomic site S2\n",
    "S2= eval(input(\"Enter % of {} for atomic site S2: \\n S2 should be <= {}% \\n\"\n",
    "               \"Now you have only {}% of {} left \\n\".format(A,trunc(max_limit),rem_A, A)))\n",
    "\n",
    "rem_A = 100-S1-S2\n",
    "n2 = n*rem_A/100\n",
    "if rem_A < 0 or S2 > trunc(max_limit):\n",
    "    raise Exception(\" Value out of range: please enter appropriate value\")\n",
    "\n",
    "\n",
    "# Assign the percentage of transition metal at the atomic site S3\n",
    "S3 = eval(input(\"Enter % of {} for atomic site S3: \\n S3 should be <= {}% \\n\"\n",
    "                \"Now you have only {}% of {} left \\n\".format(A, trunc(max_limit), rem_A, A)))\n",
    "\n",
    "rem_A = 100-S1-S2-S3\n",
    "if rem_A <0 or S2 > trunc(max_limit):\n",
    "    raise Exception(\" Value out of range: please enter appropriate value\")\n",
    "\n",
    "\n",
    "# Assign the percentage of transition metal at the atomic site S4\n",
    "S4= eval(input(\"Enter % of {} for atomic site S4: \\n S4 should be <= {}% \\n\"\n",
    "               \"Now you have only {}% of {} left\".format(A,trunc(max_limit),rem_A, A)))\n",
    "\n",
    "rem_A = 100-S1-S2-S3-S4\n",
    "if rem_A <0 or S2 > trunc(max_limit):\n",
    "    raise Exception(\" Value out of range: please enter appropriate value\")\n",
    "\n",
    "# Convert Percentage into numbers\n",
    "y_transformed = (y*16/100)/16\n",
    "x_transformed = 1-y_transformed\n",
    "S1_tranformed = S1*n/100\n",
    "S2_tranformed = S2*n/100\n",
    "S3_tranformed = S3*n/100\n",
    "S4_tranformed = S4*n/100\n",
    "print('=====================================')\n",
    "\n",
    "print(\"Transition metal: \", A,\"\\nChalcogen: \", B, \"\\nx: \", x_transformed, \"\\ny: \", y_transformed,\n",
    "      \"\\nS1: \", S1_tranformed, \"\\nS2: \", S2_tranformed, \"\\nS3: \", S3_tranformed, \"\\nS4:\", S4_tranformed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b403fe84-1a58-4ac5-8a70-abcdc49aeab7",
   "metadata": {},
   "source": [
    "### Suresh and Dharmendra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f397d46b-1077-422e-abc9-635a3c0697c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import trunc\n",
    "import random\n",
    "\n",
    "def generate_new_input():\n",
    "    # Enter transition metal\n",
    "    # A = input(\"Enter transition metal: Ni, Co, Cr or Mn \\n\")\n",
    "\n",
    "    trans_metal_dic = {1:'Ni', 2:'Co', 3:'Cr', 4:'Mn'}\n",
    "    chalcogens_dic = {5:'S', 6: 'Se', 7:'Te'}\n",
    "\n",
    "    # generate random number (0,1,2,3) and assign accordingly (Ni, Co, Cr, Mn)\n",
    "    temp_1 = random.sample(range(1, 5), 1)[0]\n",
    "    A = trans_metal_dic[temp_1]\n",
    "\n",
    "    temp_2 = random.sample(range(5, 8), 1)[0]\n",
    "    B = chalcogens_dic[temp_2]\n",
    "\n",
    "    # B= input(\"Enter Chalcogen: S, Se or  Te \\n\")\n",
    "    # if B not in ['S', 'Se', 'Te']:\n",
    "    #     raise Exception(\"Invalid entry, choose one chalcogen element\")\n",
    "\n",
    "    # Enter the percentage of substituted transition metal\n",
    "    # y= int(input(\"Concentration of {} less than equals to 62.5% \\n\".format(A)))\n",
    "    y = random.uniform(10,62.5)\n",
    "\n",
    "\n",
    "    x= 100-y  # percentage of Fe\n",
    "\n",
    "    # if y> 62.5:\n",
    "    #     raise Exception(\" Enter y less than 62.5\")\n",
    "\n",
    "    n = 16*y/100 # Total number of substituted transition metal\n",
    "\n",
    "    max_limit = 100*4/n # Calculate maximum nuber of transition metal on sites\n",
    "\n",
    "    # Assign the percentage of transition metal at the atomic site S1\n",
    "\n",
    "    # S1= eval(input(\"Enter % of {} for atomic site S1: \\n S1 should be <= {}% \\n\".format(A,trunc(max_limit))))\n",
    "    S1 = random.uniform(0, min(max_limit,100))\n",
    "\n",
    "\n",
    "\n",
    "    # if S1> max_limit:\n",
    "    #     raise Exception(\" Value out of range: please check S1's maximum value\")\n",
    "\n",
    "    rem_A = 100-S1 # Remaining percentage of transition metal\n",
    "    n1 = n * rem_A / 100 # Remaining number of transition metal\n",
    "\n",
    "\n",
    "    # Assign the percentage of transition metal at the atomic site S2\n",
    "    # S2 = eval(input(\"Enter % of {} for atomic site S2: \\n S2 should be <= {}% \\n\"\n",
    "    #                \"Now you have only {}% of {} left \\n\".format(A,trunc(max_limit),rem_A, A)))\n",
    "\n",
    "    S2 = random.uniform(0, min(max_limit, rem_A))\n",
    "\n",
    "\n",
    "    rem_A = 100 - S1 - S2\n",
    "    n2 = n * rem_A / 100\n",
    "    # if rem_A < 0 or S2 > trunc(max_limit):\n",
    "    #     raise Exception(\" Value out of range: please enter appropriate value\")\n",
    "\n",
    "\n",
    "    # Assign the percentage of transition metal at the atomic site S3\n",
    "    # S3 = eval(input(\"Enter % of {} for atomic site S3: \\n S3 should be <= {}% \\n\"\n",
    "    #                 \"Now you have only {}% of {} left \\n\".format(A, trunc(max_limit), rem_A, A)))\n",
    "    S3 = random.uniform(0, min(rem_A, max_limit))\n",
    "\n",
    "    rem_A = 100-S1-S2-S3\n",
    "\n",
    "    # if rem_A <0 or S2 > trunc(max_limit):\n",
    "    #     raise Exception(\" Value out of range: please enter appropriate value\")\n",
    "\n",
    "\n",
    "    # Assign the percentage of transition metal at the atomic site S4\n",
    "    # S4 = eval(input(\"Enter % of {} for atomic site S4: \\n S4 should be <= {}% \\n\"\n",
    "    #                \"Now you have only {}% of {} left\".format(A,trunc(max_limit),rem_A, A)))\n",
    "    S4 = random.uniform(0, min(rem_A, max_limit))\n",
    "    S4 = rem_A\n",
    "\n",
    "\n",
    "    rem_A = 100-S1-S2-S3-S4\n",
    "    # if rem_A <0 or S2 > trunc(max_limit):\n",
    "    #     raise Exception(\" Value out of range: please enter appropriate value\")\n",
    "\n",
    "    # Convert Percentage into numbers\n",
    "    y_transformed = (y*16/100)/16\n",
    "    x_transformed = 1-y_transformed\n",
    "    S1_tranformed = S1*n/100\n",
    "    S2_tranformed = S2*n/100\n",
    "    S3_tranformed = S3*n/100\n",
    "    S4_tranformed = S4*n/100\n",
    "\n",
    "    if S4_tranformed > 4:\n",
    "        # call model\n",
    "        print(\"Invalid input\")\n",
    "        return 0\n",
    "    else:\n",
    "        return [A,B,x_transformed,y_transformed,S1_tranformed,S2_tranformed,S3_tranformed,S4_tranformed]\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7faef4-c6fd-4b6f-825b-6cfe7cf5e53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load standard scaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fca416ae-939a-4015-ab33-f410bb0bde26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_on_random_sample(N_samples, output_file):\n",
    "    import pandas as pd\n",
    "    import pickle as pkl\n",
    "    from sklearn.metrics import r2_score, mean_absolute_error,mean_squared_error\n",
    "    from tensorflow.keras.models import load_model\n",
    "    \n",
    "    for iteration in range(N_samples):\n",
    "\n",
    "        # create random dataset here\n",
    "        cols = ['Fe','S1','S2','S3','S4','Ni','Co','Cr','Mn','Se','S','Te'] # list for cols to scale\n",
    "        df_new = pd.DataFrame(columns=cols)\n",
    "        data = [0]*12\n",
    "        df_new.loc[len(df_new)] = data\n",
    "        sample = generate_new_input()\n",
    "        \n",
    "        if sample == 0:\n",
    "            continue\n",
    "        \n",
    "        transition_metal = sample[0]\n",
    "        chalcogen = sample[1]\n",
    "\n",
    "        df_new['Fe'] = sample[2]\n",
    "        df_new[transition_metal] = sample[3]\n",
    "        df_new[chalcogen] = 1\n",
    "        df_new['S1'] = sample[4]\n",
    "        df_new['S2'] = sample[5]\n",
    "        df_new['S3'] = sample[6]\n",
    "        df_new['S4'] = sample[7]\n",
    "\n",
    "        X_test = df_new\n",
    "\n",
    "        print(X_test)\n",
    "\n",
    "        # load standard scaler\n",
    "        scaler = pkl.load(open('../models/standard_scaler/scaler.pkl', 'rb'))\n",
    "\n",
    "        # transform input data using saved standard scaler\n",
    "        cols_to_scale = ['Fe','S1','S2','S3','S4','Ni','Co','Cr','Mn','Se','S','Te'] # list for cols to scale\n",
    "        X_test[cols_to_scale] = scaler.transform(X_test[cols_to_scale]) # scale test data\n",
    "\n",
    "\n",
    "        # load base models\n",
    "        ANN_model = load_model(\"../models/base_models/ann.h5\")\n",
    "        svr = pkl.load(open('../models/base_models/svr.pkl', 'rb'))\n",
    "        rf_reg = pkl.load(open('../models/base_models/rf_reg.pkl', 'rb'))\n",
    "        knn_reg = pkl.load(open('../models/base_models/knn_reg.pkl', 'rb'))\n",
    "        xgb_reg = pkl.load(open('../models/base_models/xgb_reg.pkl', 'rb'))\n",
    "        dt_reg = pkl.load(open('../models/base_models/dt_reg.pkl', 'rb'))\n",
    "\n",
    "        # load meta model\n",
    "        rf_meta_final = pkl.load(open('../models/meta_model/rf_meta_final.pkl', 'rb'))\n",
    "\n",
    "        # prepare new features based on base classifiers for test set\n",
    "        y_pred_test_ann = ANN_model.predict(X_test)\n",
    "        y_pred_test_ann = y_pred_test_ann.reshape(y_pred_test_ann.shape[0],)\n",
    "        y_pred_test_svm = svr.predict(X_test)\n",
    "        y_pred_test_rf = rf_reg.predict(X_test)\n",
    "        y_pred_test_knn = knn_reg.predict(X_test)\n",
    "        y_pred_test_xgb = xgb_reg.predict(X_test)\n",
    "        y_pred_test_dt = dt_reg.predict(X_test)\n",
    "\n",
    "        # get new features from base models\n",
    "        X_test_stacking = pd.DataFrame()\n",
    "        X_test_stacking['ann'] = y_pred_test_ann\n",
    "        X_test_stacking['svm'] = y_pred_test_svm\n",
    "        X_test_stacking['rf'] = y_pred_test_rf\n",
    "        X_test_stacking['knn'] = y_pred_test_knn\n",
    "        X_test_stacking['xgb'] = y_pred_test_xgb\n",
    "        X_test_stacking['dt'] = y_pred_test_dt\n",
    "\n",
    "        # apply new features to meta classifier\n",
    "        final_prediction = rf_meta_final.predict(X_test_stacking)\n",
    "\n",
    "       # write results to file\n",
    "        df_new['M_predicted'] = final_prediction\n",
    "        df_new.to_csv(output_file)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d54ce6d-5ba2-4dec-9989-8f074a79e13f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Fe        S1        S2        S3        S4  Ni  Co  Cr        Mn  Se  \\\n",
      "0  0.439497  2.225471  1.493702  3.302103  1.946773   0   0   0  0.560503   0   \n",
      "\n",
      "   S  Te  \n",
      "0  0   1  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/suresh/anaconda3/envs/magnetism/lib/python3.8/site-packages/sklearn/base.py:329: UserWarning: Trying to unpickle estimator StandardScaler from version 1.0.2 when using version 1.1.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "2023-01-25 18:44:32.483722: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-01-25 18:44:32.483842: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2023-01-25 18:44:32.483913: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2023-01-25 18:44:32.486897: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2023-01-25 18:44:32.486982: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2023-01-25 18:44:32.487051: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2023-01-25 18:44:32.487065: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-01-25 18:44:32.487554: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/home/suresh/anaconda3/envs/magnetism/lib/python3.8/site-packages/sklearn/base.py:329: UserWarning: Trying to unpickle estimator SVR from version 1.0.2 when using version 1.1.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/home/suresh/anaconda3/envs/magnetism/lib/python3.8/site-packages/sklearn/base.py:329: UserWarning: Trying to unpickle estimator DecisionTreeRegressor from version 1.0.2 when using version 1.1.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/home/suresh/anaconda3/envs/magnetism/lib/python3.8/site-packages/sklearn/base.py:329: UserWarning: Trying to unpickle estimator RandomForestRegressor from version 1.0.2 when using version 1.1.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/home/suresh/anaconda3/envs/magnetism/lib/python3.8/site-packages/sklearn/base.py:329: UserWarning: Trying to unpickle estimator KNeighborsRegressor from version 1.0.2 when using version 1.1.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/home/suresh/anaconda3/envs/magnetism/lib/python3.8/site-packages/sklearn/base.py:329: UserWarning: Trying to unpickle estimator DummyRegressor from version 1.0.2 when using version 1.1.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/home/suresh/anaconda3/envs/magnetism/lib/python3.8/site-packages/sklearn/base.py:329: UserWarning: Trying to unpickle estimator GradientBoostingRegressor from version 1.0.2 when using version 1.1.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 93ms/step\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'GradientBoostingRegressor' object has no attribute '_loss'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtest_on_random_sample\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43moutput/test_random.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[5], line 59\u001b[0m, in \u001b[0;36mtest_on_random_sample\u001b[0;34m(N_samples, output_file)\u001b[0m\n\u001b[1;32m     57\u001b[0m y_pred_test_rf \u001b[38;5;241m=\u001b[39m rf_reg\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[1;32m     58\u001b[0m y_pred_test_knn \u001b[38;5;241m=\u001b[39m knn_reg\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[0;32m---> 59\u001b[0m y_pred_test_xgb \u001b[38;5;241m=\u001b[39m \u001b[43mxgb_reg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     60\u001b[0m y_pred_test_dt \u001b[38;5;241m=\u001b[39m dt_reg\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[1;32m     62\u001b[0m \u001b[38;5;66;03m# get new features from base models\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/magnetism/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:1961\u001b[0m, in \u001b[0;36mGradientBoostingRegressor.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m   1957\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(\n\u001b[1;32m   1958\u001b[0m     X, dtype\u001b[38;5;241m=\u001b[39mDTYPE, order\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m\"\u001b[39m, accept_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m, reset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   1959\u001b[0m )\n\u001b[1;32m   1960\u001b[0m \u001b[38;5;66;03m# In regression we can directly return the raw value from the trees.\u001b[39;00m\n\u001b[0;32m-> 1961\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raw_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mravel()\n",
      "File \u001b[0;32m~/anaconda3/envs/magnetism/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:817\u001b[0m, in \u001b[0;36mBaseGradientBoosting._raw_predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    815\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_raw_predict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[1;32m    816\u001b[0m     \u001b[38;5;124;03m\"\"\"Return the sum of the trees raw predictions (+ init estimator).\"\"\"\u001b[39;00m\n\u001b[0;32m--> 817\u001b[0m     raw_predictions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raw_predict_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    818\u001b[0m     predict_stages(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_, X, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlearning_rate, raw_predictions)\n\u001b[1;32m    819\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m raw_predictions\n",
      "File \u001b[0;32m~/anaconda3/envs/magnetism/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:810\u001b[0m, in \u001b[0;36mBaseGradientBoosting._raw_predict_init\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    806\u001b[0m     raw_predictions \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(\n\u001b[1;32m    807\u001b[0m         shape\u001b[38;5;241m=\u001b[39m(X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_loss\u001b[38;5;241m.\u001b[39mK), dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat64\n\u001b[1;32m    808\u001b[0m     )\n\u001b[1;32m    809\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 810\u001b[0m     raw_predictions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_loss\u001b[49m\u001b[38;5;241m.\u001b[39mget_init_raw_predictions(X, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minit_)\u001b[38;5;241m.\u001b[39mastype(\n\u001b[1;32m    811\u001b[0m         np\u001b[38;5;241m.\u001b[39mfloat64\n\u001b[1;32m    812\u001b[0m     )\n\u001b[1;32m    813\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m raw_predictions\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'GradientBoostingRegressor' object has no attribute '_loss'"
     ]
    }
   ],
   "source": [
    "test_on_random_sample(10, 'output/test_random.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3797497b-5d13-4de9-b79d-e0c0fe3fbd5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.1.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f126a8-a619-4e35-8581-062c1188e7b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101aef5f-5feb-4919-80a1-f0067729dd7e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
