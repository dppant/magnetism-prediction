{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4d6f3b6-fcf1-4179-94d9-0f8e433d9091",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import r2_score, mean_absolute_error\n",
    "from sklearn.svm import SVR\n",
    "import sklearn\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68e4e6d0-a1aa-4951-9ff2-e71a2131d3ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read csv\n",
    "train = pd.read_csv('data/train_test/train.csv', header = 0)\n",
    "test = pd.read_csv('data/train_test/test.csv', header = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca4ef1fa-7e96-40d5-9364-16eb0e91726b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split X and y\n",
    "y_train = train['M']\n",
    "X_train = train.drop(columns = ['M'])\n",
    "\n",
    "y_test = test['M']\n",
    "X_test = test.drop(columns = ['M'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11354c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data normalization\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# list for cols to scale\n",
    "cols_to_scale = ['Fe','S1','S2','S3','S4','Ni','Co','Cr','Mn','Se','S','Te']\n",
    "\n",
    "#create and fit scaler using train data\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train[cols_to_scale])\n",
    "\n",
    "#scale trained data\n",
    "X_train[cols_to_scale] = scaler.transform(X_train[cols_to_scale])\n",
    "\n",
    "# scale test data\n",
    "X_test[cols_to_scale] = scaler.transform(X_test[cols_to_scale])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f307cd8a-f60e-4a83-911b-d5204d6f8059",
   "metadata": {},
   "source": [
    "# Machine Learning Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2039bb9b",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9817241a-6ca2-47e4-ba26-ee26c4f04757",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e414101-6e4c-4cb3-ad3a-be59b2d94102",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define 10-Fold CV object\n",
    "kfold = KFold(n_splits=10, shuffle=True, random_state=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0390fd1-3c2a-496d-b696-c263e4e1a013",
   "metadata": {},
   "source": [
    "## 1. Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7d63f0a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores:  [-6.62049115 -7.32942984 -6.47729331 -7.23570509 -7.03503016 -7.42770107\n",
      " -6.75655087 -7.83059039 -6.24506202 -7.06546415] \n",
      "\n",
      "Negative Mean Square Error: -7.002331806566119\n",
      "---------------------\n",
      "Scores:  [0.69703931 0.66940064 0.66956488 0.71029315 0.68987915 0.67448625\n",
      " 0.71657408 0.69660077 0.72457546 0.69525168] \n",
      "\n",
      "R2 Mean Score: 0.6943665363180347\n",
      "---------------------\n",
      "Scores:  [-2.09066843 -2.19953295 -2.09042594 -2.20123383 -2.1305333  -2.26679365\n",
      " -2.15809787 -2.26123849 -2.06059702 -2.21403773] \n",
      "\n",
      "Mean Absolute Error: -2.1673159207975177\n"
     ]
    }
   ],
   "source": [
    "# create lr model\n",
    "lr = LinearRegression()\n",
    "\n",
    "# calculate cross validation scores\n",
    "# MSE\n",
    "score = cross_val_score(lr, X_train, y_train, cv= 10, scoring='neg_mean_squared_error')\n",
    "print(\"Scores: \",score,\"\\n\\nNegative Mean Square Error:\",score.mean())\n",
    "print(\"---------------------\")\n",
    "\n",
    "# R2 Error\n",
    "score = cross_val_score(lr, X_train, y_train, cv= 10)\n",
    "print(\"Scores: \",score,\"\\n\\nR2 Mean Score:\",score.mean())\n",
    "print(\"---------------------\")\n",
    "\n",
    "# MAE\n",
    "score = cross_val_score(lr, X_train, y_train, cv= 10, scoring='neg_mean_absolute_error')\n",
    "print(\"Scores: \",score,\"\\n\\nMean Absolute Error:\",score.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b7be4c2-7270-49ee-9004-3c7d50861c3c",
   "metadata": {},
   "source": [
    "## 2. SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "30f269b6-048d-4046-a9ea-0fd005888290",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 264 candidates, totalling 1320 fits\n",
      "[CV] END ...........................C=1, gamma=1, kernel=rbf; total time=   0.3s\n",
      "[CV] END ...........................C=1, gamma=1, kernel=rbf; total time=   0.2s\n",
      "[CV] END ...........................C=1, gamma=1, kernel=rbf; total time=   0.3s\n",
      "[CV] END ...........................C=1, gamma=1, kernel=rbf; total time=   0.2s\n",
      "[CV] END ...........................C=1, gamma=1, kernel=rbf; total time=   0.3s\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "import numpy as np\n",
    "n_samples, n_features = 10, 5\n",
    "np.random.seed(0)\n",
    "parameters = {'kernel': ('rbf','poly'), 'C':[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,50,100],'gamma': [1,0.1,0.01,0.001,0.0001,0.00001]}\n",
    "svr = SVR()\n",
    "reg = GridSearchCV(svr, parameters, verbose=2)\n",
    "reg.fit(X_train,y_train)\n",
    "reg.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "41a0c834-4a06-4aa3-90e8-2b8cebf9c135",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C = 12\n",
      "0.929812946093169\n",
      "0.9325899047061833\n",
      "0.914287718723866\n",
      "0.9322598210763435\n",
      "0.9332810553004589\n",
      "0.9197125797219148\n",
      "0.9241234811272864\n",
      "0.9271868200297224\n",
      "0.9198028821157143\n",
      "0.9222827299891154\n",
      "Average = 0.9255339938883773\n",
      "-----------------------\n"
     ]
    }
   ],
   "source": [
    "# r2_score SVR\n",
    "for C in [12]:\n",
    "    summ = 0\n",
    "    print(\"C = \"+str(C))\n",
    "    for train, val in kfold.split(X_train):\n",
    "        X_train_small, y_train_small = X_train.iloc[train], y_train.iloc[train]\n",
    "        X_val, y_val = X_train.iloc[val], y_train.iloc[val]\n",
    "\n",
    "        svr = SVR(C=12)\n",
    "        svr.fit(X_train_small,y_train_small)\n",
    "\n",
    "        y_pred = svr.predict(X_val)\n",
    "        # res = mean_squared_error(y_pred, y_val)\n",
    "        \n",
    "        res = r2_score(y_pred, y_val)\n",
    "        summ = summ + res\n",
    "        print(res)\n",
    "    print(\"Average = \"+str(summ/10))\n",
    "    print(\"-----------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f372e3b9-37e7-4af4-ac7f-b8d043b80464",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C = 12\n",
      "0.583053816048711\n",
      "0.5904888753856085\n",
      "0.5723921562712055\n",
      "0.608027160803529\n",
      "0.5324099872966578\n",
      "0.5892896783246114\n",
      "0.554104512424551\n",
      "0.5928540437916852\n",
      "0.5130706872480152\n",
      "0.6062349878498415\n",
      "Average = 0.5741925905444416\n",
      "-----------------------\n"
     ]
    }
   ],
   "source": [
    "#mean absolute error SVR\n",
    "for C in [12]:\n",
    "    summ = 0\n",
    "    print(\"C = \"+str(C))\n",
    "    for train, val in kfold.split(X_train):\n",
    "        X_train_small, y_train_small = X_train.iloc[train], y_train.iloc[train]\n",
    "        X_val, y_val = X_train.iloc[val], y_train.iloc[val]\n",
    "\n",
    "        svr = SVR(C=C)\n",
    "        svr.fit(X_train_small,y_train_small)\n",
    "\n",
    "        y_pred = svr.predict(X_val)\n",
    "        # res = mean_squared_error(y_pred, y_val)\n",
    "        \n",
    "        res = mean_absolute_error(y_pred, y_val)\n",
    "        summ = summ + res\n",
    "        print(res)\n",
    "    print(\"Average = \"+str(summ/10))\n",
    "    print(\"-----------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05510dfc-a88c-4e9f-b48c-d3dd7a177e32",
   "metadata": {},
   "source": [
    "## 3. Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f50a9b63-660e-4fc0-879f-aeda03fdee16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores:  [-1.72058446 -1.72237218 -1.77819267 -1.86422235 -1.81037493 -1.11439629\n",
      " -1.22354608 -1.88503437 -1.4067101  -2.18679418] \n",
      "\n",
      "Negative Mean Square Error: -1.6712227599730596\n",
      "---------------------\n",
      "Scores:  [0.92134751 0.92171383 0.91110731 0.93177209 0.922262   0.95505482\n",
      " 0.94899879 0.92896712 0.93718971 0.9058802 ] \n",
      "\n",
      "R2 Mean Score: 0.92842933644417\n",
      "---------------------\n",
      "Scores:  [-0.56265445 -0.52033796 -0.55881602 -0.53338759 -0.57890467 -0.49616773\n",
      " -0.4649394  -0.62476902 -0.52992519 -0.61955251] \n",
      "\n",
      "Mean Absolute Error: -0.5489454539292222\n"
     ]
    }
   ],
   "source": [
    "dt = DecisionTreeRegressor()\n",
    "\n",
    "# MSE\n",
    "score = cross_val_score(dt, X_train, y_train, cv= 10, scoring='neg_mean_squared_error')\n",
    "print(\"Scores: \",score,\"\\n\\nNegative Mean Square Error:\",score.mean())\n",
    "\n",
    "print(\"---------------------\")\n",
    "# R2 Error\n",
    "score = cross_val_score(dt, X_train, y_train, cv= 10)\n",
    "print(\"Scores: \",score,\"\\n\\nR2 Mean Score:\",score.mean())\n",
    "print(\"---------------------\")\n",
    "\n",
    "\n",
    "# MAE\n",
    "score = cross_val_score(dt, X_train, y_train, cv= 10, scoring='neg_mean_absolute_error')\n",
    "print(\"Scores: \",score,\"\\n\\nMean Absolute Error:\",score.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c7e585-36b3-453d-8360-61270cab722e",
   "metadata": {},
   "source": [
    "## 4. Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0bea0c8-29c0-4c11-84c4-df1c87eeb456",
   "metadata": {},
   "source": [
    "### Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7284799e-9eed-4b03-8557-79a3b167ec5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn import ensemble\n",
    "\n",
    "# Set the parameters by cross-validation\n",
    "tuned_parameters = {'n_estimators': [20,50,100,200,300,400,500,600, 700,800,900, 1000], 'min_samples_split': [1, 2, 3, 4, 5, 6,7,8,9,10,11,12,13,20]}\n",
    "\n",
    "# reg = ensemble.RandomForestRegressor(n_estimators=500, n_jobs=1, verbose=1)\n",
    "reg = GridSearchCV(ensemble.RandomForestRegressor(), tuned_parameters, cv=5, n_jobs=-1, verbose=1)\n",
    "reg.fit(X_train, y_train)\n",
    "#print(reg.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4b048dd4-e39e-4eec-9734-4b9e52878b59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores:  [-1.44137979 -1.55470469 -1.24497257 -1.51900609 -1.50560078 -1.1926084\n",
      " -1.17261787 -1.809275   -1.28921469 -1.63515467] \n",
      "\n",
      "Negative Mean Square Error: -1.4364534531856132\n",
      "---------------------\n",
      "Scores:  [0.93399495 0.9300816  0.93611262 0.93914451 0.93358843 0.94768831\n",
      " 0.95026586 0.93037603 0.94364026 0.92917286] \n",
      "\n",
      "R2 Mean Score: 0.9374065443525794\n",
      "---------------------\n",
      "Scores:  [-0.55160816 -0.54255994 -0.52570619 -0.55584898 -0.57789195 -0.54035153\n",
      " -0.49956881 -0.6272368  -0.53718422 -0.58186608] \n",
      "\n",
      "Mean Absolute Error: -0.5539822667195661\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf_reg = RandomForestRegressor(n_estimators=500, min_samples_split = 13)\n",
    "\n",
    "# MSE\n",
    "score = cross_val_score(rf_reg, X_train, y_train, cv= 10, scoring='neg_mean_squared_error')\n",
    "print(\"Scores: \", score,\"\\n\\nNegative Mean Square Error:\",score.mean())\n",
    "\n",
    "\n",
    "print(\"---------------------\")\n",
    "\n",
    "# R2 Error\n",
    "score = cross_val_score(rf_reg, X_train, y_train, cv= 10)\n",
    "print(\"Scores: \",score,\"\\n\\nR2 Mean Score:\",score.mean())\n",
    "\n",
    "# MAE\n",
    "print(\"---------------------\")\n",
    "score = cross_val_score(rf_reg, X_train, y_train, cv= 10, scoring='neg_mean_absolute_error')\n",
    "print(\"Scores: \",score,\"\\n\\nMean Absolute Error:\",score.mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f04e69b-bac8-4975-a38d-be1bc6b05333",
   "metadata": {},
   "source": [
    "## 5. KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "84f69dad-a273-45bd-878c-462d9e141574",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores:  [-1.57284425 -2.07397086 -1.64270622 -2.0523524  -2.11677536 -1.40599941\n",
      " -1.30825049 -1.83604152 -1.45116284 -1.94825641] \n",
      "\n",
      "Negative Mean Square Error: -1.740835976548275\n",
      "---------------------\n",
      "Scores:  [0.92802498 0.90645201 0.91619836 0.91782687 0.90668751 0.93838307\n",
      " 0.9451211  0.92886187 0.9359997  0.9159676 ] \n",
      "\n",
      "R2 Mean Score: 0.9239523059691424\n",
      "---------------------\n",
      "Scores:  [-0.61521189 -0.65325514 -0.62359297 -0.64534108 -0.68876757 -0.5984206\n",
      " -0.5579729  -0.70775447 -0.60454851 -0.63049919] \n",
      "\n",
      "Mean Absolute Error: -0.6325364312605288\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "knn = KNeighborsRegressor()\n",
    "\n",
    "# MSE\n",
    "score = cross_val_score(knn, X_train, y_train, cv= 10, scoring='neg_mean_squared_error')\n",
    "print(\"Scores: \",score,\"\\n\\nNegative Mean Square Error:\",score.mean())\n",
    "\n",
    "print(\"---------------------\")\n",
    "# R2 Error\n",
    "score = cross_val_score(knn, X_train, y_train, cv= 10)\n",
    "print(\"Scores: \",score,\"\\n\\nR2 Mean Score:\",score.mean())\n",
    "\n",
    "# MAE\n",
    "print(\"---------------------\")\n",
    "score = cross_val_score(knn, X_train, y_train, cv= 10, scoring='neg_mean_absolute_error')\n",
    "print(\"Scores: \",score,\"\\n\\nMean Absolute Error:\",score.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf18d16-fa03-4e0d-87a9-ec78ed748f74",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d8a6b837-44ca-4609-883a-76185db4fe68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores:  [-1.51229102 -1.82667785 -1.23848509 -1.55040293 -1.54734647 -1.47612781\n",
      " -1.27373632 -1.80597346 -1.80597028 -1.77264267] \n",
      "\n",
      "Negative Mean Square Error: -1.580965389935382\n",
      "---------------------\n",
      "Scores:  [0.93079596 0.91760634 0.93681945 0.93792418 0.93178929 0.93530974\n",
      " 0.94657129 0.93002686 0.92035171 0.92356941] \n",
      "\n",
      "R2 Mean Score: 0.9310764240447537\n",
      "---------------------\n",
      "Scores:  [-0.6724323  -0.6963745  -0.63253687 -0.67211028 -0.69701847 -0.67943528\n",
      " -0.63676067 -0.7305399  -0.76143233 -0.70871043] \n",
      "\n",
      "Mean Absolute Error: -0.6887351040981338\n"
     ]
    }
   ],
   "source": [
    "from sklearn import ensemble\n",
    "\n",
    "reg = ensemble.GradientBoostingRegressor()\n",
    "\n",
    "# MSE\n",
    "score = cross_val_score(reg, X_train, y_train, cv= 10, scoring='neg_mean_squared_error')\n",
    "print(\"Scores: \",score,\"\\n\\nNegative Mean Square Error:\",score.mean())\n",
    "\n",
    "print(\"---------------------\")\n",
    "# R2 Error\n",
    "score = cross_val_score(reg, X_train, y_train, cv= 10)\n",
    "print(\"Scores: \",score,\"\\n\\nR2 Mean Score:\",score.mean())\n",
    "\n",
    "\n",
    "# MAE\n",
    "print(\"---------------------\")\n",
    "score = cross_val_score(reg, X_train, y_train, cv= 10, scoring='neg_mean_absolute_error')\n",
    "print(\"Scores: \",score,\"\\n\\nMean Absolute Error:\",score.mean())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ade9e9d-e6b2-4faa-8ec9-8504e5c30d9a",
   "metadata": {},
   "source": [
    "# Deep Learning Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "38a8aff2-3e83-4651-a8e0-944f60f4ea82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout \n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bdfc4788-6341-4782-b042-c447f5c18e37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 8.8421 - val_loss: 2.3529\n",
      "Epoch 2/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.1406 - val_loss: 2.1760\n",
      "Epoch 3/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.9351 - val_loss: 1.8428\n",
      "Epoch 4/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.7964 - val_loss: 1.8418\n",
      "Epoch 5/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.7745 - val_loss: 1.9075\n",
      "Epoch 6/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.6887 - val_loss: 1.8922\n",
      "Epoch 7/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.7341 - val_loss: 1.7550\n",
      "Epoch 8/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.6443 - val_loss: 1.7157\n",
      "Epoch 9/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.6093 - val_loss: 1.6829\n",
      "Epoch 10/500\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 1.6021 - val_loss: 2.0114\n",
      "Epoch 11/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.7703 - val_loss: 1.7980\n",
      "Epoch 12/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.7533 - val_loss: 1.6790\n",
      "Epoch 13/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.6553 - val_loss: 1.8011\n",
      "Epoch 14/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.5644 - val_loss: 1.8192\n",
      "Epoch 15/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.5564 - val_loss: 1.6402\n",
      "Epoch 16/500\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 1.5003 - val_loss: 1.6176\n",
      "Epoch 17/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.5078 - val_loss: 1.5467\n",
      "Epoch 18/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.4988 - val_loss: 1.5106\n",
      "Epoch 19/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.4657 - val_loss: 1.5042\n",
      "Epoch 20/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.4703 - val_loss: 1.4700\n",
      "Epoch 21/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.5397 - val_loss: 1.9288\n",
      "Epoch 22/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.5804 - val_loss: 1.5544\n",
      "Epoch 23/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.4936 - val_loss: 1.5071\n",
      "Epoch 24/500\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 1.4524 - val_loss: 1.5034\n",
      "Epoch 25/500\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 1.4776 - val_loss: 1.6438\n",
      "Epoch 26/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.5104 - val_loss: 1.2966\n",
      "Epoch 27/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.4175 - val_loss: 1.4449\n",
      "Epoch 28/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.4651 - val_loss: 1.4333\n",
      "Epoch 29/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.3338 - val_loss: 1.3259\n",
      "Epoch 30/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.3622 - val_loss: 1.3922\n",
      "Epoch 31/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.3070 - val_loss: 1.4427\n",
      "Epoch 32/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.3614 - val_loss: 1.2911\n",
      "Epoch 33/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.2624 - val_loss: 1.2243\n",
      "Epoch 34/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.2716 - val_loss: 1.2915\n",
      "Epoch 35/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.3586 - val_loss: 1.3668\n",
      "Epoch 36/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.3166 - val_loss: 1.2096\n",
      "Epoch 37/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.3796 - val_loss: 1.3191\n",
      "Epoch 38/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.4512 - val_loss: 1.4946\n",
      "Epoch 39/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.4279 - val_loss: 1.2159\n",
      "Epoch 40/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.3630 - val_loss: 1.2620\n",
      "Epoch 41/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.3228 - val_loss: 1.2067\n",
      "Epoch 42/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.2161 - val_loss: 1.2318\n",
      "Epoch 43/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.3014 - val_loss: 1.2414\n",
      "Epoch 44/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.3405 - val_loss: 1.3804\n",
      "Epoch 45/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.3300 - val_loss: 1.2369\n",
      "Epoch 46/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.2661 - val_loss: 1.3608\n",
      "Epoch 47/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.2410 - val_loss: 1.2490\n",
      "Epoch 48/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.1992 - val_loss: 1.1724\n",
      "Epoch 49/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.1835 - val_loss: 1.0676\n",
      "Epoch 50/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.1562 - val_loss: 1.1507\n",
      "Epoch 51/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.1596 - val_loss: 1.1897\n",
      "Epoch 52/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.1539 - val_loss: 1.1309\n",
      "Epoch 53/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.1415 - val_loss: 1.1614\n",
      "Epoch 54/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.2243 - val_loss: 1.3727\n",
      "Epoch 55/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.2589 - val_loss: 1.1743\n",
      "Epoch 56/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.1964 - val_loss: 1.2383\n",
      "Epoch 57/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.1519 - val_loss: 1.1933\n",
      "Epoch 58/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.1347 - val_loss: 1.2075\n",
      "Epoch 59/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.1399 - val_loss: 1.3711\n",
      "Epoch 60/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.2387 - val_loss: 1.2152\n",
      "Epoch 61/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.3486 - val_loss: 1.2007\n",
      "Epoch 62/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.6574 - val_loss: 1.7128\n",
      "Epoch 63/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.3081 - val_loss: 1.2529\n",
      "Epoch 64/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.2128 - val_loss: 1.2451\n",
      "12/12 [==============================] - 0s 2ms/step\n",
      "1.245126104879579 0.9407629356257532 0.5721343136889306\n",
      "Epoch 1/500\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 9.0082 - val_loss: 2.1853\n",
      "Epoch 2/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.2506 - val_loss: 2.2324\n",
      "Epoch 3/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.0908 - val_loss: 1.9112\n",
      "Epoch 4/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.8582 - val_loss: 1.9625\n",
      "Epoch 5/500\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 1.7849 - val_loss: 1.8901\n",
      "Epoch 6/500\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 1.7155 - val_loss: 1.6427\n",
      "Epoch 7/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.6982 - val_loss: 1.6120\n",
      "Epoch 8/500\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 1.6253 - val_loss: 1.6507\n",
      "Epoch 9/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.6180 - val_loss: 1.7936\n",
      "Epoch 10/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.5884 - val_loss: 1.7277\n",
      "Epoch 11/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.5618 - val_loss: 1.6495\n",
      "Epoch 12/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.5484 - val_loss: 1.7502\n",
      "Epoch 13/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.5242 - val_loss: 1.7277\n",
      "Epoch 14/500\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 1.4824 - val_loss: 1.5850\n",
      "Epoch 15/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.4511 - val_loss: 1.6540\n",
      "Epoch 16/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.4976 - val_loss: 1.9571\n",
      "Epoch 17/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.5629 - val_loss: 2.1153\n",
      "Epoch 18/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.5266 - val_loss: 1.6196\n",
      "Epoch 19/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.3838 - val_loss: 1.4897\n",
      "Epoch 20/500\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 1.3895 - val_loss: 1.6664\n",
      "Epoch 21/500\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 1.3770 - val_loss: 1.5849\n",
      "Epoch 22/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.3580 - val_loss: 1.5250\n",
      "Epoch 23/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.3323 - val_loss: 1.5366\n",
      "Epoch 24/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.2843 - val_loss: 1.5846\n",
      "Epoch 25/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.2796 - val_loss: 1.5031\n",
      "Epoch 26/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.3079 - val_loss: 1.6762\n",
      "Epoch 27/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.2130 - val_loss: 1.8014\n",
      "Epoch 28/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.2759 - val_loss: 1.6441\n",
      "Epoch 29/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.2403 - val_loss: 1.6738\n",
      "Epoch 30/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.2483 - val_loss: 1.7193\n",
      "Epoch 31/500\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 1.2639 - val_loss: 1.7914\n",
      "Epoch 32/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.2539 - val_loss: 1.6211\n",
      "Epoch 33/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.1898 - val_loss: 1.5848\n",
      "Epoch 34/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.1970 - val_loss: 1.5950\n",
      "12/12 [==============================] - 0s 1ms/step\n",
      "1.5950299879502075 0.9256737052291945 0.6324354788260484\n",
      "Epoch 1/500\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 11.8275 - val_loss: 2.2964\n",
      "Epoch 2/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.3555 - val_loss: 2.3750\n",
      "Epoch 3/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 2.1070 - val_loss: 2.3767\n",
      "Epoch 4/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.8751 - val_loss: 2.3597\n",
      "Epoch 5/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.8632 - val_loss: 1.9721\n",
      "Epoch 6/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.7344 - val_loss: 2.0936\n",
      "Epoch 7/500\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 1.7242 - val_loss: 2.1692\n",
      "Epoch 8/500\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 1.6972 - val_loss: 2.0378\n",
      "Epoch 9/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.6495 - val_loss: 1.8062\n",
      "Epoch 10/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.6317 - val_loss: 1.9645\n",
      "Epoch 11/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.6087 - val_loss: 1.9844\n",
      "Epoch 12/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.5947 - val_loss: 2.0360\n",
      "Epoch 13/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.6294 - val_loss: 2.1825\n",
      "Epoch 14/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.7048 - val_loss: 1.7373\n",
      "Epoch 15/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.5542 - val_loss: 2.0580\n",
      "Epoch 16/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.5561 - val_loss: 2.0192\n",
      "Epoch 17/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.4884 - val_loss: 1.8817\n",
      "Epoch 18/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.4936 - val_loss: 1.6761\n",
      "Epoch 19/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.4659 - val_loss: 1.7176\n",
      "Epoch 20/500\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 1.5076 - val_loss: 1.6862\n",
      "Epoch 21/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.4623 - val_loss: 1.9553\n",
      "Epoch 22/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.4468 - val_loss: 1.5340\n",
      "Epoch 23/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.4287 - val_loss: 1.6810\n",
      "Epoch 24/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.3909 - val_loss: 1.7607\n",
      "Epoch 25/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.3811 - val_loss: 1.6860\n",
      "Epoch 26/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.3483 - val_loss: 1.4575\n",
      "Epoch 27/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.3920 - val_loss: 1.5468\n",
      "Epoch 28/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.3180 - val_loss: 1.5011\n",
      "Epoch 29/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.3793 - val_loss: 1.4613\n",
      "Epoch 30/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.3168 - val_loss: 1.5222\n",
      "Epoch 31/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.3290 - val_loss: 1.5222\n",
      "Epoch 32/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.3723 - val_loss: 1.4676\n",
      "Epoch 33/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.3479 - val_loss: 1.4967\n",
      "Epoch 34/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.2600 - val_loss: 1.4938\n",
      "Epoch 35/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.2418 - val_loss: 1.5588\n",
      "Epoch 36/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.2637 - val_loss: 1.3045\n",
      "Epoch 37/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.3343 - val_loss: 1.9859\n",
      "Epoch 38/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.5401 - val_loss: 1.4109\n",
      "Epoch 39/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.3496 - val_loss: 1.4808\n",
      "Epoch 40/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.3898 - val_loss: 1.4371\n",
      "Epoch 41/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.3481 - val_loss: 1.6120\n",
      "Epoch 42/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.2892 - val_loss: 1.4082\n",
      "Epoch 43/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.2621 - val_loss: 1.3611\n",
      "Epoch 44/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.2721 - val_loss: 1.3833\n",
      "Epoch 45/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.3925 - val_loss: 1.4268\n",
      "Epoch 46/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.2443 - val_loss: 1.5055\n",
      "Epoch 47/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.2099 - val_loss: 1.4238\n",
      "Epoch 48/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.2178 - val_loss: 1.3308\n",
      "Epoch 49/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.2432 - val_loss: 1.3325\n",
      "Epoch 50/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.2094 - val_loss: 1.4717\n",
      "Epoch 51/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.1644 - val_loss: 1.3292\n",
      "12/12 [==============================] - 0s 1ms/step\n",
      "1.3291772838137033 0.9450088000597037 0.5538877578185242\n",
      "Epoch 1/500\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 12.1665 - val_loss: 2.8320\n",
      "Epoch 2/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.3929 - val_loss: 2.4908\n",
      "Epoch 3/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 2.0349 - val_loss: 2.1284\n",
      "Epoch 4/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.8586 - val_loss: 2.1367\n",
      "Epoch 5/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.7996 - val_loss: 2.0612\n",
      "Epoch 6/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.7382 - val_loss: 2.1417\n",
      "Epoch 7/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.7012 - val_loss: 1.9267\n",
      "Epoch 8/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.7277 - val_loss: 2.0310\n",
      "Epoch 9/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.6666 - val_loss: 1.7957\n",
      "Epoch 10/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.6451 - val_loss: 2.2932\n",
      "Epoch 11/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.6150 - val_loss: 2.1121\n",
      "Epoch 12/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.6602 - val_loss: 1.6757\n",
      "Epoch 13/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.5488 - val_loss: 1.8833\n",
      "Epoch 14/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.5255 - val_loss: 1.7444\n",
      "Epoch 15/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.5462 - val_loss: 1.9142\n",
      "Epoch 16/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.5408 - val_loss: 1.6256\n",
      "Epoch 17/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.5539 - val_loss: 1.5962\n",
      "Epoch 18/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.5675 - val_loss: 1.7779\n",
      "Epoch 19/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.5225 - val_loss: 1.6962\n",
      "Epoch 20/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.4984 - val_loss: 1.5682\n",
      "Epoch 21/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.5354 - val_loss: 2.0478\n",
      "Epoch 22/500\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 1.4708 - val_loss: 1.5548\n",
      "Epoch 23/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.4437 - val_loss: 1.4662\n",
      "Epoch 24/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.4266 - val_loss: 1.6086\n",
      "Epoch 25/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.5053 - val_loss: 1.4818\n",
      "Epoch 26/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.4240 - val_loss: 1.7583\n",
      "Epoch 27/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.4263 - val_loss: 1.6253\n",
      "Epoch 28/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.4099 - val_loss: 1.5613\n",
      "Epoch 29/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.3233 - val_loss: 1.4562\n",
      "Epoch 30/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.3313 - val_loss: 1.6530\n",
      "Epoch 31/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.3077 - val_loss: 1.4942\n",
      "Epoch 32/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.3252 - val_loss: 1.4230\n",
      "Epoch 33/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.2895 - val_loss: 1.4743\n",
      "Epoch 34/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.2626 - val_loss: 1.4349\n",
      "Epoch 35/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.2524 - val_loss: 1.6348\n",
      "Epoch 36/500\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 1.3410 - val_loss: 1.5456\n",
      "Epoch 37/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.2573 - val_loss: 1.6762\n",
      "Epoch 38/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.3027 - val_loss: 2.1764\n",
      "Epoch 39/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.4310 - val_loss: 1.3192\n",
      "Epoch 40/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.4021 - val_loss: 1.3983\n",
      "Epoch 41/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.3495 - val_loss: 1.6637\n",
      "Epoch 42/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.2801 - val_loss: 1.4459\n",
      "Epoch 43/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.2450 - val_loss: 1.6617\n",
      "Epoch 44/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.2349 - val_loss: 1.3598\n",
      "Epoch 45/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.2127 - val_loss: 1.8412\n",
      "Epoch 46/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.3945 - val_loss: 1.4190\n",
      "Epoch 47/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.3091 - val_loss: 1.3266\n",
      "Epoch 48/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.2098 - val_loss: 1.5940\n",
      "Epoch 49/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.2863 - val_loss: 1.4155\n",
      "Epoch 50/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.3487 - val_loss: 1.3847\n",
      "Epoch 51/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.2129 - val_loss: 1.5719\n",
      "Epoch 52/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.2019 - val_loss: 1.2767\n",
      "Epoch 53/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.1591 - val_loss: 1.4096\n",
      "Epoch 54/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.2994 - val_loss: 1.6320\n",
      "Epoch 55/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.3196 - val_loss: 1.3310\n",
      "Epoch 56/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.4196 - val_loss: 1.6331\n",
      "Epoch 57/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.3471 - val_loss: 1.3210\n",
      "Epoch 58/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.2180 - val_loss: 1.3526\n",
      "Epoch 59/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.2026 - val_loss: 1.2973\n",
      "Epoch 60/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.1501 - val_loss: 1.3934\n",
      "Epoch 61/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.1944 - val_loss: 1.3750\n",
      "Epoch 62/500\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 1.1813 - val_loss: 1.3419\n",
      "Epoch 63/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.2109 - val_loss: 1.5314\n",
      "Epoch 64/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.2253 - val_loss: 1.3864\n",
      "Epoch 65/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.1661 - val_loss: 1.4561\n",
      "Epoch 66/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.1516 - val_loss: 1.3486\n",
      "Epoch 67/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.1250 - val_loss: 1.3769\n",
      "12/12 [==============================] - 0s 920us/step\n",
      "1.3769093371968795 0.9397057916591698 0.6065196503215544\n",
      "Epoch 1/500\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 9.6807 - val_loss: 2.2152\n",
      "Epoch 2/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.2875 - val_loss: 2.4909\n",
      "Epoch 3/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.2231 - val_loss: 1.4041\n",
      "Epoch 4/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.9231 - val_loss: 1.5218\n",
      "Epoch 5/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.8193 - val_loss: 1.2314\n",
      "Epoch 6/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.7598 - val_loss: 1.2039\n",
      "Epoch 7/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.7406 - val_loss: 1.2014\n",
      "Epoch 8/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.6594 - val_loss: 1.3351\n",
      "Epoch 9/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.6362 - val_loss: 1.2016\n",
      "Epoch 10/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.6357 - val_loss: 1.2059\n",
      "Epoch 11/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.6400 - val_loss: 1.2059\n",
      "Epoch 12/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.5823 - val_loss: 1.1993\n",
      "Epoch 13/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.7034 - val_loss: 1.3260\n",
      "Epoch 14/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.5074 - val_loss: 1.2064\n",
      "Epoch 15/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.5161 - val_loss: 1.2376\n",
      "Epoch 16/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.5142 - val_loss: 1.3310\n",
      "Epoch 17/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.4774 - val_loss: 1.2102\n",
      "Epoch 18/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.5177 - val_loss: 1.2841\n",
      "Epoch 19/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.5902 - val_loss: 1.3906\n",
      "Epoch 20/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.5511 - val_loss: 1.4138\n",
      "Epoch 21/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.6051 - val_loss: 1.6019\n",
      "Epoch 22/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.5247 - val_loss: 1.2483\n",
      "Epoch 23/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.4437 - val_loss: 1.1684\n",
      "Epoch 24/500\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 1.3595 - val_loss: 1.2992\n",
      "Epoch 25/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.3941 - val_loss: 1.1407\n",
      "Epoch 26/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.3333 - val_loss: 1.2210\n",
      "Epoch 27/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.3424 - val_loss: 1.2995\n",
      "Epoch 28/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.4031 - val_loss: 1.3286\n",
      "Epoch 29/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.3789 - val_loss: 1.1779\n",
      "Epoch 30/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.3158 - val_loss: 1.2220\n",
      "Epoch 31/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.2699 - val_loss: 1.3023\n",
      "Epoch 32/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.3162 - val_loss: 1.2856\n",
      "Epoch 33/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.3166 - val_loss: 1.2277\n",
      "Epoch 34/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.3145 - val_loss: 1.3071\n",
      "Epoch 35/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.3442 - val_loss: 1.2449\n",
      "Epoch 36/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.2703 - val_loss: 1.2389\n",
      "Epoch 37/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.2766 - val_loss: 1.3511\n",
      "Epoch 38/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.3295 - val_loss: 1.4195\n",
      "Epoch 39/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.2249 - val_loss: 1.2560\n",
      "Epoch 40/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.3000 - val_loss: 1.1234\n",
      "Epoch 41/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.2732 - val_loss: 1.3314\n",
      "Epoch 42/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.2652 - val_loss: 1.3217\n",
      "Epoch 43/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.2405 - val_loss: 1.3970\n",
      "Epoch 44/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.2440 - val_loss: 1.3148\n",
      "Epoch 45/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.3665 - val_loss: 1.3400\n",
      "Epoch 46/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.2164 - val_loss: 1.2805\n",
      "Epoch 47/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.1975 - val_loss: 1.2258\n",
      "Epoch 48/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.1640 - val_loss: 1.3697\n",
      "Epoch 49/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.2426 - val_loss: 1.2232\n",
      "Epoch 50/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.2395 - val_loss: 1.4454\n",
      "Epoch 51/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.2144 - val_loss: 1.2473\n",
      "Epoch 52/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.1939 - val_loss: 1.1111\n",
      "Epoch 53/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.2708 - val_loss: 1.4831\n",
      "Epoch 54/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.3005 - val_loss: 1.1818\n",
      "Epoch 55/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.3219 - val_loss: 1.0940\n",
      "Epoch 56/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.2068 - val_loss: 1.3037\n",
      "Epoch 57/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.2332 - val_loss: 1.4808\n",
      "Epoch 58/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.2688 - val_loss: 1.1791\n",
      "Epoch 59/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.1774 - val_loss: 1.2135\n",
      "Epoch 60/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.1957 - val_loss: 1.3301\n",
      "Epoch 61/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.2068 - val_loss: 1.1385\n",
      "Epoch 62/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.2101 - val_loss: 1.2176\n",
      "Epoch 63/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.2020 - val_loss: 1.1677\n",
      "Epoch 64/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.2445 - val_loss: 1.1142\n",
      "Epoch 65/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.1627 - val_loss: 1.2339\n",
      "Epoch 66/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.1863 - val_loss: 1.3101\n",
      "Epoch 67/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.3834 - val_loss: 1.5081\n",
      "Epoch 68/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.2548 - val_loss: 1.1638\n",
      "Epoch 69/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.1734 - val_loss: 1.1910\n",
      "Epoch 70/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.2022 - val_loss: 1.2250\n",
      "12/12 [==============================] - 0s 781us/step\n",
      "1.2250078423059774 0.933626545747334 0.5302973962436631\n",
      "Epoch 1/500\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 10.7628 - val_loss: 2.5338\n",
      "Epoch 2/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 2.2110 - val_loss: 2.1703\n",
      "Epoch 3/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.9697 - val_loss: 2.1006\n",
      "Epoch 4/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.8557 - val_loss: 2.0493\n",
      "Epoch 5/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.8448 - val_loss: 1.8605\n",
      "Epoch 6/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.6990 - val_loss: 1.8470\n",
      "Epoch 7/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.6376 - val_loss: 1.8620\n",
      "Epoch 8/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.6530 - val_loss: 1.8163\n",
      "Epoch 9/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.6423 - val_loss: 1.8259\n",
      "Epoch 10/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.6068 - val_loss: 1.7893\n",
      "Epoch 11/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.5734 - val_loss: 1.8991\n",
      "Epoch 12/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.6165 - val_loss: 1.8946\n",
      "Epoch 13/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.6111 - val_loss: 2.0082\n",
      "Epoch 14/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.5783 - val_loss: 1.9780\n",
      "Epoch 15/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.5727 - val_loss: 1.9559\n",
      "Epoch 16/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.5241 - val_loss: 1.9371\n",
      "Epoch 17/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.4717 - val_loss: 1.8958\n",
      "Epoch 18/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.5334 - val_loss: 1.9247\n",
      "Epoch 19/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.5268 - val_loss: 1.8334\n",
      "Epoch 20/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.5152 - val_loss: 1.9819\n",
      "Epoch 21/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.4604 - val_loss: 1.8949\n",
      "Epoch 22/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.4361 - val_loss: 2.2276\n",
      "Epoch 23/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.4721 - val_loss: 1.8619\n",
      "Epoch 24/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.5536 - val_loss: 1.7181\n",
      "Epoch 25/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.3693 - val_loss: 1.7437\n",
      "Epoch 26/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.3158 - val_loss: 1.8322\n",
      "Epoch 27/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.3166 - val_loss: 2.3643\n",
      "Epoch 28/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.3884 - val_loss: 1.7263\n",
      "Epoch 29/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.2542 - val_loss: 1.7482\n",
      "Epoch 30/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.2781 - val_loss: 1.8567\n",
      "Epoch 31/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.2871 - val_loss: 1.7687\n",
      "Epoch 32/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.2245 - val_loss: 1.6872\n",
      "Epoch 33/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.2760 - val_loss: 1.7313\n",
      "Epoch 34/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.3475 - val_loss: 1.8554\n",
      "Epoch 35/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.3474 - val_loss: 2.0908\n",
      "Epoch 36/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.2656 - val_loss: 1.8557\n",
      "Epoch 37/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.2422 - val_loss: 1.7605\n",
      "Epoch 38/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.1777 - val_loss: 1.8816\n",
      "Epoch 39/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.2225 - val_loss: 1.8208\n",
      "Epoch 40/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.2102 - val_loss: 1.6992\n",
      "Epoch 41/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.1772 - val_loss: 1.8949\n",
      "Epoch 42/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.2821 - val_loss: 1.8118\n",
      "Epoch 43/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.2051 - val_loss: 1.7681\n",
      "Epoch 44/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.1988 - val_loss: 1.7558\n",
      "Epoch 45/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.1665 - val_loss: 1.7293\n",
      "Epoch 46/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.1530 - val_loss: 1.7300\n",
      "Epoch 47/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.2668 - val_loss: 1.6689\n",
      "Epoch 48/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.3495 - val_loss: 2.1124\n",
      "Epoch 49/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.4874 - val_loss: 1.6672\n",
      "Epoch 50/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.3052 - val_loss: 1.7902\n",
      "Epoch 51/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.1646 - val_loss: 1.7543\n",
      "Epoch 52/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.1779 - val_loss: 1.7872\n",
      "Epoch 53/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.1285 - val_loss: 1.7796\n",
      "Epoch 54/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.1416 - val_loss: 1.6934\n",
      "Epoch 55/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.1272 - val_loss: 1.7167\n",
      "Epoch 56/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.1541 - val_loss: 1.8485\n",
      "Epoch 57/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.1762 - val_loss: 1.6829\n",
      "Epoch 58/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.1067 - val_loss: 1.6386\n",
      "Epoch 59/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.0865 - val_loss: 1.7636\n",
      "Epoch 60/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.1122 - val_loss: 1.8683\n",
      "Epoch 61/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.1854 - val_loss: 1.8893\n",
      "Epoch 62/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.1450 - val_loss: 1.7943\n",
      "Epoch 63/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.1743 - val_loss: 1.7862\n",
      "Epoch 64/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.1348 - val_loss: 1.7248\n",
      "Epoch 65/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.0581 - val_loss: 1.6731\n",
      "Epoch 66/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.1851 - val_loss: 1.8133\n",
      "Epoch 67/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.1101 - val_loss: 1.6801\n",
      "Epoch 68/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.1071 - val_loss: 1.7603\n",
      "Epoch 69/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.1345 - val_loss: 1.8681\n",
      "Epoch 70/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.1523 - val_loss: 2.0514\n",
      "Epoch 71/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.1687 - val_loss: 1.7216\n",
      "Epoch 72/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.1423 - val_loss: 1.7932\n",
      "Epoch 73/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.1234 - val_loss: 1.7657\n",
      "12/12 [==============================] - 0s 1ms/step\n",
      "1.765705328545964 0.9225697237854612 0.6529698412495775\n",
      "Epoch 1/500\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 10.4195 - val_loss: 2.0728\n",
      "Epoch 2/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.5839 - val_loss: 1.8158\n",
      "Epoch 3/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 2.1128 - val_loss: 1.5558\n",
      "Epoch 4/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.8666 - val_loss: 1.4154\n",
      "Epoch 5/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.8938 - val_loss: 1.4368\n",
      "Epoch 6/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.9986 - val_loss: 1.3814\n",
      "Epoch 7/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.7839 - val_loss: 1.2984\n",
      "Epoch 8/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.6851 - val_loss: 1.3901\n",
      "Epoch 9/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.6320 - val_loss: 1.4265\n",
      "Epoch 10/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.6216 - val_loss: 1.2808\n",
      "Epoch 11/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.5930 - val_loss: 1.3111\n",
      "Epoch 12/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.5474 - val_loss: 1.2740\n",
      "Epoch 13/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.5452 - val_loss: 1.2881\n",
      "Epoch 14/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.5259 - val_loss: 1.2444\n",
      "Epoch 15/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.5403 - val_loss: 1.5632\n",
      "Epoch 16/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.5348 - val_loss: 1.1594\n",
      "Epoch 17/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.4266 - val_loss: 1.1178\n",
      "Epoch 18/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.4577 - val_loss: 1.2591\n",
      "Epoch 19/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.4543 - val_loss: 1.1231\n",
      "Epoch 20/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.4201 - val_loss: 1.1419\n",
      "Epoch 21/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.4070 - val_loss: 1.1922\n",
      "Epoch 22/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.3857 - val_loss: 1.1541\n",
      "Epoch 23/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.3757 - val_loss: 1.3077\n",
      "Epoch 24/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.4171 - val_loss: 1.1236\n",
      "Epoch 25/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.3105 - val_loss: 1.0517\n",
      "Epoch 26/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.2572 - val_loss: 1.1177\n",
      "Epoch 27/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.3251 - val_loss: 1.2557\n",
      "Epoch 28/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.3510 - val_loss: 1.1309\n",
      "Epoch 29/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.2974 - val_loss: 1.2571\n",
      "Epoch 30/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.3385 - val_loss: 1.1987\n",
      "Epoch 31/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.3278 - val_loss: 1.1715\n",
      "Epoch 32/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.2941 - val_loss: 1.1804\n",
      "Epoch 33/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.3072 - val_loss: 1.0673\n",
      "Epoch 34/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.2865 - val_loss: 1.1851\n",
      "Epoch 35/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.3055 - val_loss: 1.0660\n",
      "Epoch 36/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.2100 - val_loss: 1.2181\n",
      "Epoch 37/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.2992 - val_loss: 1.1082\n",
      "Epoch 38/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.2478 - val_loss: 1.1621\n",
      "Epoch 39/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.1914 - val_loss: 1.0528\n",
      "Epoch 40/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.2071 - val_loss: 1.2181\n",
      "12/12 [==============================] - 0s 2ms/step\n",
      "1.2180633290882485 0.9261986311638397 0.5589833685403391\n",
      "Epoch 1/500\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 9.1618 - val_loss: 3.2080\n",
      "Epoch 2/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.4192 - val_loss: 2.3998\n",
      "Epoch 3/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 2.0469 - val_loss: 2.1964\n",
      "Epoch 4/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.9573 - val_loss: 2.3838\n",
      "Epoch 5/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.7838 - val_loss: 1.9804\n",
      "Epoch 6/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.6779 - val_loss: 2.0074\n",
      "Epoch 7/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.6293 - val_loss: 2.1337\n",
      "Epoch 8/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.6633 - val_loss: 2.0133\n",
      "Epoch 9/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.7737 - val_loss: 2.3637\n",
      "Epoch 10/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.6931 - val_loss: 2.1860\n",
      "Epoch 11/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.6014 - val_loss: 1.9191\n",
      "Epoch 12/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.6109 - val_loss: 1.9434\n",
      "Epoch 13/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.6324 - val_loss: 2.0666\n",
      "Epoch 14/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.6083 - val_loss: 2.1205\n",
      "Epoch 15/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.5579 - val_loss: 1.9124\n",
      "Epoch 16/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.4841 - val_loss: 1.9215\n",
      "Epoch 17/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.4567 - val_loss: 1.8353\n",
      "Epoch 18/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.4218 - val_loss: 1.9521\n",
      "Epoch 19/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.3950 - val_loss: 1.9778\n",
      "Epoch 20/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.4325 - val_loss: 1.8827\n",
      "Epoch 21/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.4326 - val_loss: 1.7723\n",
      "Epoch 22/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.3574 - val_loss: 1.8443\n",
      "Epoch 23/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.3350 - val_loss: 1.9741\n",
      "Epoch 24/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.3085 - val_loss: 1.7366\n",
      "Epoch 25/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.3006 - val_loss: 1.7345\n",
      "Epoch 26/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.2931 - val_loss: 1.8911\n",
      "Epoch 27/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.3123 - val_loss: 1.7692\n",
      "Epoch 28/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.2424 - val_loss: 1.6464\n",
      "Epoch 29/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.2254 - val_loss: 1.8121\n",
      "Epoch 30/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.2472 - val_loss: 1.9158\n",
      "Epoch 31/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.2919 - val_loss: 1.7402\n",
      "Epoch 32/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.2505 - val_loss: 1.6868\n",
      "Epoch 33/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.1966 - val_loss: 1.6184\n",
      "Epoch 34/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.1579 - val_loss: 1.8719\n",
      "Epoch 35/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.1608 - val_loss: 1.5858\n",
      "Epoch 36/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.1847 - val_loss: 1.5849\n",
      "Epoch 37/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.1530 - val_loss: 1.7100\n",
      "Epoch 38/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.1922 - val_loss: 1.5870\n",
      "Epoch 39/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.2354 - val_loss: 1.7481\n",
      "Epoch 40/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.3511 - val_loss: 1.5430\n",
      "Epoch 41/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.4374 - val_loss: 2.3470\n",
      "Epoch 42/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.3465 - val_loss: 1.5986\n",
      "Epoch 43/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.2947 - val_loss: 1.6540\n",
      "Epoch 44/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.1685 - val_loss: 1.6086\n",
      "Epoch 45/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.1300 - val_loss: 1.6874\n",
      "Epoch 46/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.1264 - val_loss: 1.5949\n",
      "Epoch 47/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.1697 - val_loss: 1.7484\n",
      "Epoch 48/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.1880 - val_loss: 1.7864\n",
      "Epoch 49/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.2399 - val_loss: 1.6944\n",
      "Epoch 50/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.2382 - val_loss: 1.7391\n",
      "Epoch 51/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.1881 - val_loss: 1.6751\n",
      "Epoch 52/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.1804 - val_loss: 1.5784\n",
      "Epoch 53/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.2489 - val_loss: 1.6049\n",
      "Epoch 54/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.2396 - val_loss: 1.5976\n",
      "Epoch 55/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.2261 - val_loss: 1.5622\n",
      "12/12 [==============================] - 0s 1ms/step\n",
      "1.5622126928885642 0.9303642065058838 0.6001483426072047\n",
      "Epoch 1/500\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 11.1087 - val_loss: 2.2651\n",
      "Epoch 2/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 2.3774 - val_loss: 1.9727\n",
      "Epoch 3/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 2.0370 - val_loss: 1.8103\n",
      "Epoch 4/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.8986 - val_loss: 1.7959\n",
      "Epoch 5/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.8116 - val_loss: 1.7255\n",
      "Epoch 6/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.7518 - val_loss: 1.6525\n",
      "Epoch 7/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.6860 - val_loss: 1.6781\n",
      "Epoch 8/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.7496 - val_loss: 1.7384\n",
      "Epoch 9/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.7612 - val_loss: 1.9772\n",
      "Epoch 10/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.7262 - val_loss: 1.6258\n",
      "Epoch 11/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.6332 - val_loss: 1.5500\n",
      "Epoch 12/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.5963 - val_loss: 1.7549\n",
      "Epoch 13/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.6227 - val_loss: 1.6991\n",
      "Epoch 14/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.5437 - val_loss: 1.6295\n",
      "Epoch 15/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.5184 - val_loss: 1.5322\n",
      "Epoch 16/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.5002 - val_loss: 1.6236\n",
      "Epoch 17/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.4363 - val_loss: 1.6089\n",
      "Epoch 18/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.4347 - val_loss: 1.5648\n",
      "Epoch 19/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.4502 - val_loss: 1.5577\n",
      "Epoch 20/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.4392 - val_loss: 1.5914\n",
      "Epoch 21/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.4720 - val_loss: 1.6584\n",
      "Epoch 22/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.5054 - val_loss: 1.7178\n",
      "Epoch 23/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.4159 - val_loss: 1.5851\n",
      "Epoch 24/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.3584 - val_loss: 1.5917\n",
      "Epoch 25/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.3209 - val_loss: 1.5722\n",
      "Epoch 26/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.3135 - val_loss: 1.6067\n",
      "Epoch 27/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.4652 - val_loss: 1.8988\n",
      "Epoch 28/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.4079 - val_loss: 1.7045\n",
      "Epoch 29/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.3430 - val_loss: 1.5975\n",
      "Epoch 30/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.2656 - val_loss: 1.4412\n",
      "Epoch 31/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.2347 - val_loss: 1.5536\n",
      "Epoch 32/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.2349 - val_loss: 1.4837\n",
      "Epoch 33/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.2468 - val_loss: 1.4968\n",
      "Epoch 34/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.2101 - val_loss: 1.5983\n",
      "Epoch 35/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.2858 - val_loss: 1.6295\n",
      "Epoch 36/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.3907 - val_loss: 1.4486\n",
      "Epoch 37/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.3366 - val_loss: 1.6468\n",
      "Epoch 38/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.3647 - val_loss: 1.7411\n",
      "Epoch 39/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.3081 - val_loss: 1.5394\n",
      "Epoch 40/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.2103 - val_loss: 1.5589\n",
      "Epoch 41/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.2068 - val_loss: 1.7355\n",
      "Epoch 42/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.2438 - val_loss: 1.4361\n",
      "Epoch 43/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.1736 - val_loss: 1.5040\n",
      "Epoch 44/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.4055 - val_loss: 1.6627\n",
      "Epoch 45/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.3766 - val_loss: 1.5424\n",
      "Epoch 46/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.5894 - val_loss: 1.6096\n",
      "Epoch 47/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.3212 - val_loss: 1.5416\n",
      "Epoch 48/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.2523 - val_loss: 1.5246\n",
      "Epoch 49/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.1976 - val_loss: 1.4137\n",
      "Epoch 50/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.1513 - val_loss: 1.5008\n",
      "Epoch 51/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.1380 - val_loss: 1.5325\n",
      "Epoch 52/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.1212 - val_loss: 1.4913\n",
      "Epoch 53/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.1481 - val_loss: 1.5431\n",
      "Epoch 54/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.1986 - val_loss: 1.4903\n",
      "Epoch 55/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.1707 - val_loss: 1.4966\n",
      "Epoch 56/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.1318 - val_loss: 1.6253\n",
      "Epoch 57/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.1305 - val_loss: 1.5044\n",
      "Epoch 58/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.1473 - val_loss: 1.5647\n",
      "Epoch 59/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.1085 - val_loss: 1.4455\n",
      "Epoch 60/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.1119 - val_loss: 1.4836\n",
      "Epoch 61/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.1026 - val_loss: 1.4662\n",
      "Epoch 62/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.1013 - val_loss: 1.5173\n",
      "Epoch 63/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.1429 - val_loss: 1.6717\n",
      "Epoch 64/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.1858 - val_loss: 1.5325\n",
      "12/12 [==============================] - 0s 2ms/step\n",
      "1.532521336114814 0.9279003003469056 0.5422081675346143\n",
      "Epoch 1/500\n",
      "13/13 [==============================] - 1s 11ms/step - loss: 9.1648 - val_loss: 2.4841\n",
      "Epoch 2/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.2898 - val_loss: 2.3063\n",
      "Epoch 3/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 2.1689 - val_loss: 2.2167\n",
      "Epoch 4/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.8879 - val_loss: 2.2326\n",
      "Epoch 5/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.7701 - val_loss: 2.1099\n",
      "Epoch 6/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.7322 - val_loss: 2.1712\n",
      "Epoch 7/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.7780 - val_loss: 2.3119\n",
      "Epoch 8/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.7750 - val_loss: 1.9858\n",
      "Epoch 9/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.6663 - val_loss: 2.1439\n",
      "Epoch 10/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.6734 - val_loss: 1.9662\n",
      "Epoch 11/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.5661 - val_loss: 1.9401\n",
      "Epoch 12/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.5363 - val_loss: 2.0749\n",
      "Epoch 13/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.5819 - val_loss: 1.9217\n",
      "Epoch 14/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.6240 - val_loss: 1.9328\n",
      "Epoch 15/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.4984 - val_loss: 2.2263\n",
      "Epoch 16/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.6960 - val_loss: 1.7911\n",
      "Epoch 17/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.6050 - val_loss: 1.9144\n",
      "Epoch 18/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.5510 - val_loss: 1.8210\n",
      "Epoch 19/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.4209 - val_loss: 1.8101\n",
      "Epoch 20/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.3874 - val_loss: 1.7349\n",
      "Epoch 21/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.4304 - val_loss: 1.9113\n",
      "Epoch 22/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.3979 - val_loss: 1.8585\n",
      "Epoch 23/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.4299 - val_loss: 1.7764\n",
      "Epoch 24/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.3394 - val_loss: 1.7127\n",
      "Epoch 25/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.3970 - val_loss: 1.7701\n",
      "Epoch 26/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.3973 - val_loss: 1.6822\n",
      "Epoch 27/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.2974 - val_loss: 1.7977\n",
      "Epoch 28/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.4150 - val_loss: 1.6564\n",
      "Epoch 29/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.3713 - val_loss: 1.7168\n",
      "Epoch 30/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.3377 - val_loss: 1.6341\n",
      "Epoch 31/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.3259 - val_loss: 1.6271\n",
      "Epoch 32/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.2503 - val_loss: 1.6885\n",
      "Epoch 33/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.2971 - val_loss: 1.7164\n",
      "Epoch 34/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.4059 - val_loss: 1.7091\n",
      "Epoch 35/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.2671 - val_loss: 1.7234\n",
      "Epoch 36/500\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 1.2477 - val_loss: 1.5661\n",
      "Epoch 37/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.3027 - val_loss: 1.8065\n",
      "Epoch 38/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.3698 - val_loss: 1.6448\n",
      "Epoch 39/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.2587 - val_loss: 1.6060\n",
      "Epoch 40/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.2381 - val_loss: 1.6956\n",
      "Epoch 41/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.2974 - val_loss: 1.8111\n",
      "Epoch 42/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.3855 - val_loss: 1.5857\n",
      "Epoch 43/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.3664 - val_loss: 1.5331\n",
      "Epoch 44/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.2966 - val_loss: 1.6507\n",
      "Epoch 45/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.2372 - val_loss: 1.5016\n",
      "Epoch 46/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.1974 - val_loss: 1.6581\n",
      "Epoch 47/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.3120 - val_loss: 1.9778\n",
      "Epoch 48/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.2044 - val_loss: 1.5032\n",
      "Epoch 49/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.1998 - val_loss: 1.6194\n",
      "Epoch 50/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.2227 - val_loss: 1.4797\n",
      "Epoch 51/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.1762 - val_loss: 1.4542\n",
      "Epoch 52/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.1199 - val_loss: 1.4698\n",
      "Epoch 53/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.2518 - val_loss: 1.5400\n",
      "Epoch 54/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.3287 - val_loss: 1.8565\n",
      "Epoch 55/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.2480 - val_loss: 1.6165\n",
      "Epoch 56/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.1742 - val_loss: 1.5188\n",
      "Epoch 57/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.1427 - val_loss: 1.4444\n",
      "Epoch 58/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.1429 - val_loss: 1.4981\n",
      "Epoch 59/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.1670 - val_loss: 1.5061\n",
      "Epoch 60/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.1179 - val_loss: 1.5150\n",
      "Epoch 61/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.1090 - val_loss: 1.5495\n",
      "Epoch 62/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.1129 - val_loss: 1.4550\n",
      "Epoch 63/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.1601 - val_loss: 1.5899\n",
      "Epoch 64/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.1095 - val_loss: 1.4452\n",
      "Epoch 65/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.1452 - val_loss: 1.4515\n",
      "Epoch 66/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.1235 - val_loss: 1.4525\n",
      "Epoch 67/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.0998 - val_loss: 1.5025\n",
      "Epoch 68/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.1148 - val_loss: 1.4488\n",
      "Epoch 69/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.1249 - val_loss: 1.5378\n",
      "Epoch 70/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.0948 - val_loss: 1.4787\n",
      "Epoch 71/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.1019 - val_loss: 1.5845\n",
      "Epoch 72/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.2083 - val_loss: 1.6307\n",
      "12/12 [==============================] - 0s 775us/step\n",
      "1.6306667707259148 0.9329619411077681 0.613319318913317\n",
      "-----------------------\n",
      "Average =  1.4480420013509854 0.9324772581231013 0.5862903635743774\n",
      "-----------------------\n"
     ]
    }
   ],
   "source": [
    "sum_mse, sum_r2, sum_mae = 0, 0, 0\n",
    "for train, val in kfold.split(X_train):\n",
    "    X_train_small, y_train_small = X_train.iloc[train], y_train.iloc[train]\n",
    "    X_val, y_val = X_train.iloc[val], y_train.iloc[val]\n",
    "\n",
    "    # define model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(254, activation= 'relu', input_shape = (12,))) #input shape = X_train[0].shape\n",
    "    model.add(Dense(64, activation= 'relu'))\n",
    "    # model.add(Dense(4, activation= 'relu'))\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    model.compile(optimizer= tf.keras.optimizers.Adam(learning_rate = 0.01), loss='mse')\n",
    "\n",
    "    #early stopping\n",
    "    callback = tf.keras.callbacks.EarlyStopping(patience=15, monitor='val_loss', mode = 'min')\n",
    "\n",
    "    history = model.fit(X_train_small,y_train_small, epochs = 500,  batch_size=256, verbose=1, validation_data = (X_val,y_val), callbacks = [callback])\n",
    "    \n",
    "    y_pred = model.predict(X_val)\n",
    "    mse = mean_squared_error(y_pred, y_val)\n",
    "    r2 = r2_score(y_pred, y_val)\n",
    "    mae = mean_absolute_error(y_pred, y_val)\n",
    "    sum_mse = sum_mse + mse\n",
    "    sum_r2 = sum_r2 + r2\n",
    "    sum_mae = sum_mae + mae\n",
    "    print(str(mse), str(r2), str(mae))\n",
    "    \n",
    "print(\"-----------------------\")  \n",
    "print(\"Average = \", str(sum_mse/10), str(sum_r2/10), str(sum_mae/10))\n",
    "print(\"-----------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bcd17895-3230-41d7-8aa2-eec8dae989d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import keras\n",
    "from matplotlib import pyplot as plt\n",
    "plt.plot(history.history['loss'][1:])\n",
    "plt.plot(history.history['val_loss'][1:])\n",
    "# plt.title('model accuracy')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "6cf61953-fd9a-4542-9694-d4abe9a2e6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('ann.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
